<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	Redmagic
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="Redmagic" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
					
					<h1><a href="index.html">Redmagic</a></h1>
					<p class="subtitle">FFFF</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="self" href="index.html">Home</a></li>
						
						  <li id=""><a target="_self" href="archives.html">Archives</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">













								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">
<div itemscope itemtype="http://schema.org/Blog">


	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2020-06-07T20:56:47+08:00" itemprop="datePublished">2020/6/7</time>
			</div>
			
			 
			
		</div>
		<h1 class="title" itemprop="name"><a href="15915346076929.html" itemprop="url">
		Ansible å¿«é€Ÿå…¥é—¨</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>Ansible æ˜¯ä¸€ä¸ª IT è‡ªåŠ¨åŒ–è½¯ä»¶ï¼Œç±»ä¼¼äº Puppet å’Œ Chefï¼Œæ˜¯å®ç° Infra-as-a-code çš„ä¸€ç§å·¥å…·ã€‚</p>

<h2 id="toc_0">QuickStart</h2>

<h3 id="toc_1">ç†è§£ Ansible å¦‚ä½•æ§åˆ¶è¿œç¨‹æœåŠ¡å™¨</h3>

<p>Ansible çš„æ‰€æœ‰æ“ä½œæ˜¯åŸºäº ssh åè®®çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ ssh å‘½ä»¤åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šæ‰§è¡Œå‘½ä»¤ï¼š</p>

<pre><code class="language-bash">$ ssh root@ip &#39;ping baidu.com&#39;
PING baidu.com (39.156.69.79) 56(84) bytes of data.
64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=48 time=7.83 ms
64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=48 time=3.43 ms
64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=3 ttl=48 time=3.45 ms
64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=4 ttl=48 time=3.46 ms
</code></pre>

<p>åœ¨ Ansible ä¸­ç¼–å†™çš„è„šæœ¬æœ€ç»ˆä¹Ÿä¼šè¢«ç¿»è¯‘æˆç±»ä¼¼ä¸Šé¢å‘½ä»¤çš„æ–¹å¼è¢«æ‰§è¡Œã€‚</p>

<p>åœ¨ Ansible æ‰§è¡Œçš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦ä¸¤ç§è§’è‰²çš„èŠ‚ç‚¹ï¼Œåˆ†åˆ«å¯¹åº” ssh çš„ client å’Œ serverï¼š</p>

<ul>
<li>ç®¡ç†èŠ‚ç‚¹ï¼ˆæ‰§è¡Œ ansible å‘½ä»¤çš„æœºå™¨ï¼‰</li>
<li>æ‰˜ç®¡èŠ‚ç‚¹ï¼ˆè¢« ansible çš„ç®¡ç†çš„æœºå™¨ï¼‰</li>
</ul>

<p>Ansible çš„ç®¡ç†èŠ‚ç‚¹ç›®å‰æ”¯æŒç±» unix ç³»ç»Ÿï¼Œä¹Ÿå°±æ˜¯ linux å’Œ macosã€‚æš‚æ—¶ä¸æ”¯æŒ windows ä½œä¸ºç®¡ç†èŠ‚ç‚¹ã€‚ç®¡ç†èŠ‚ç‚¹å¯ä»¥æ˜¯è‡ªå·±æœ¬åœ°çš„ç”µè„‘ï¼Œä½†æ˜¯ç”±äºç§æœ‰åŒ–éƒ¨ç½²æ—¶æˆ‘ä»¬é¢å¯¹çš„é€šå¸¸éƒ½æ˜¯å®¢æˆ·çš„å†…ç½‘ç¯å¢ƒï¼Œä¸€èˆ¬éƒ½æ— æ³•åœ¨è‡ªå·±çš„å¼€å‘æœºç›´æ¥è®¿é—®ã€‚ä¸ºäº†ç®€åŒ–ä½¿ç”¨æ–¹å¼ï¼Œæˆ‘ä»¬é€‰æ‹©å®¢æˆ·çš„ä¸€å°æœåŠ¡å™¨åŠä½œä¸ºç®¡ç†èŠ‚ç‚¹ä¹ŸåŒæ—¶ä½œä¸ºæ‰˜ç®¡èŠ‚ç‚¹ï¼Œæ‰€æœ‰ ansible çš„æ“ä½œæ€»æ˜¯ä»ç®¡ç†èŠ‚ç‚¹å‘èµ·ã€‚</p>

<p>æ—¢ç„¶ Ansible æ˜¯åŸºäº ssh åè®®å®ç°çš„ï¼Œæˆ‘ä»¬å¿…é¡»å†³å®šä»¥å“ªä¸ª<strong>ç”¨æˆ·</strong>çš„èº«ä»½ç™»é™†ï¼Œä»¥ä½•ç§æ–¹å¼è¿›è¡Œ <strong>ssh è®¤è¯</strong>ï¼Œä»¥åŠç¡®ä¿ç™»é™†ç”¨æˆ·æœ‰ <strong>sudo</strong> çš„æƒé™ã€‚ssh å¸¸ç”¨çš„è®¤è¯æ–¹å¼æ”¯æŒå¯†ç å’Œè¯ä¹¦ä¸¤ç§ï¼Œç”±äºæˆ‘ä»¬å¸Œæœ›è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼Œä¸æƒ³åœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é¢‘ç¹çš„è¾“å…¥å¯†ç ï¼Œå› æ­¤é…ç½®è¯ä¹¦è®¤è¯æ˜¯æ¯”è¾ƒå¥½çš„é€‰æ‹©ã€‚å¦å¤–å¾ˆå¤šå®¢æˆ·ç¯å¢ƒä¸‹ sudo ä¹Ÿéœ€è¦é¢å¤–çš„å¯†ç ï¼Œå› æ­¤éœ€è¦åœ¨åˆå§‹åŒ–ç¯å¢ƒæ—¶é…ç½® ssh çš„ç™»é™†ç”¨æˆ·å¯ä»¥å…å¯†çš„è¿›è¡Œ sudo æ“ä½œã€‚</p>

<p>æ€»ç»“ä¸€ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦ï¼š</p>

<ul>
<li>é€‰æ‹©ä¸€å°å®¢æˆ·å†…ç½‘çš„æœåŠ¡å™¨ä½œä¸ºç®¡ç†èŠ‚ç‚¹ï¼Œè¯¥èŠ‚ç‚¹é€šå¸¸ä¹Ÿæ˜¯æˆ‘ä»¬çš„æ‰˜ç®¡èŠ‚ç‚¹</li>
<li>å¯¹æ‰˜ç®¡èŠ‚ç‚¹é…ç½®åŸºäºè¯ä¹¦çš„ ssh å…å¯†ç™»é™†</li>
<li>ç¡®ä¿ ssh ç™»é™†ç”¨æˆ·å¯ä»¥å…å¯†è¿›è¡Œ sudo æ“ä½œ</li>
</ul>

<h3 id="toc_2">Inventory File</h3>

<p>Ansible å¯åŒæ—¶æ“ä½œå±äºä¸€ä¸ªç»„çš„å¤šå°ä¸»æœº,ç»„å’Œä¸»æœºä¹‹é—´çš„å…³ç³»é€šè¿‡ inventory æ–‡ä»¶é…ç½®ã€‚é»˜è®¤çš„æ–‡ä»¶è·¯å¾„ä¸º <code>/etc/ansible/hosts</code> ã€‚ä¸è¿‡æˆ‘ä»¬é€šå¸¸ä¸æŠŠ  inventory file æ”¾åœ¨ç³»ç»Ÿç›®å½•ä¸‹ï¼Œè€Œæ˜¯æ”¾åœ¨å•ç‹¬çš„é…ç½®ç›®å½•ã€‚</p>

<p>æˆ‘ä»¬è¯•ç€å†™ä¸€ä¸ª inventory file :</p>

<pre><code class="language-yaml">[webserver]
host1
host2
</code></pre>

<p>ä¿å­˜ä¸º <code>hosts</code> ï¼Œç„¶åé€šè¿‡ ansible çš„å‘½ä»¤è¡Œæ‰§è¡Œ adhoc å‘½ä»¤</p>

<pre><code class="language-yaml">$ ansible all -i hosts -m ping
host1 | UNREACHABLE! =&gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh: ssh: Could not resolve hostname host1: nodename nor servname provided, or not known&quot;,
    &quot;unreachable&quot;: true
}
host2 | UNREACHABLE! =&gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh: ssh: Could not resolve hostname host2: nodename nor servname provided, or not known&quot;,
    &quot;unreachable&quot;: true
}
</code></pre>

<p>å…¶ä¸­ <code>all</code> æ˜¯ <code>&lt;host-pattern&gt;</code> ,  <code>all</code> æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ patternï¼ŒåŒ¹é…æ‰€æœ‰ hostsã€‚æç¤ºæŠ¥é”™æ˜¯é¢„æœŸçš„ç»“æœï¼Œå› ä¸º host1, host2 å¹¶ä¸å­˜åœ¨ã€‚</p>

<h3 id="toc_3">Playbookï¼ŒRoleï¼ŒTask</h3>

<p>ä¸Šä¸€èŠ‚å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ ansible æ‰§è¡Œ adhoc å‘½ä»¤ï¼Œä½†æ˜¯å¤§éƒ¨åˆ†æ—¶å€™æˆ‘ä»¬ç”¨çš„æ›´å¤šçš„æ˜¯ <code>ansible-playbook</code> å‘½ä»¤ã€‚Playbook æ˜¯ ansible çš„ä»»åŠ¡ç¼–æ’è¯­è¨€ï¼Œé€šè¿‡ YAML æ¥æè¿°ã€‚å…³äº Playbook å’Œ roleï¼Œ task çš„å…³ç³»ï¼Œä¸€å¥è¯å°±å¯ä»¥è¯´æ¸…æ¥šï¼šå‰§æœ¬ (playbook) å¼€å§‹ï¼Œè§’è‰²ä»¬ï¼ˆrole) ä¾æ¬¡ç™»ä¸Šèˆå°ï¼Œå®Œæˆè‡ªå·±çš„ä»»åŠ¡ (task)ã€‚</p>

<p>playbook ä¸€èˆ¬æ˜¯ ansible æ‰§è¡Œçš„å…¥å£ï¼›role æ›´åƒæ˜¯æ¨¡å—ï¼Œæ˜¯æˆ‘ä»¬å¤ç”¨ä»£ç çš„åŸºæœ¬å•ä½ï¼›task æ˜¯ä¸€ä¸ªä¸ªå…·ä½“çš„å®ç°ã€‚</p>

<p>å…ˆä»ä¸€ä¸ªä¸è€ƒè™‘å¤ç”¨çš„ playbook å¼€å§‹ï¼š</p>

<pre><code class="language-yaml">- hosts: all
  tasks:
    - name: install vim
      yum:
        name: vim
        state: present

    - name: install jdk
      yum:
        name: openjdk
        state: present
</code></pre>

<p>è¿™ä¸ª playbook ä¼šåœ¨æ‰€æœ‰æœºå™¨ä¸Šå®‰è£… vim å’Œ openjdkã€‚yum æ˜¯ ansible æä¾›çš„ä¸€ä¸ªæ¨¡å—ï¼Œansible æ‹¥æœ‰éå¸¸å¼ºå¤§çš„ç”Ÿæ€ï¼Œæˆ‘ä»¬éœ€è¦å‡ ä¹æ‰€æœ‰æ“ä½œéƒ½è¢« ansible å¾ˆå¥½çš„å°è£…äº†ã€‚æ‰€æœ‰æ¨¡å—çš„æ–‡æ¡£å¯ä»¥å‚è€ƒï¼š<a href="https://docs.ansible.com/ansible/latest/modules/modules_by_category.html">https://docs.ansible.com/ansible/latest/modules/modules_by_category.html</a></p>

<p>éšç€ task è¶Šæ¥è¶Šå¤šï¼Œplaybook ä¼šå˜å¾—éå¸¸é•¿è€Œä¸”ä¸å®¹æ˜“ç»´æŠ¤ï¼Œä¸­é—´å¦‚æœæœ‰é‡å¤éƒ¨åˆ†ä¹Ÿéš¾ä»¥å®ç°ä»£ç å¤ç”¨ã€‚è¿™ä¸ªæ—¶å€™å°±è½®åˆ°è§’è‰²ï¼ˆroleï¼‰ ç™»åœºäº†ã€‚</p>

<h3 id="toc_4">ç¼–å†™å¯å¤ç”¨çš„è„šæœ¬</h3>

<p>role ä»ä»£ç ä¸Šçœ‹å°±æ˜¯ä¸€ä¸ªç‰¹å®šç»“æ„çš„ç›®å½•ï¼Œå…¸å‹çš„ role ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š</p>

<pre><code class="language-yaml">site.yml
webservers.yml
fooservers.yml
roles/
   common/
     files/
     templates/
     tasks/
     handlers/
     vars/
     defaults/
     meta/
   webservers/
     files/
     templates/
     tasks/
     handlers/
     vars/
     defaults/
     meta/
</code></pre>

<p>æ¯ä¸ªç›®å½•ä¸‹é»˜è®¤çš„å…¥å£éƒ½æ˜¯ <code>main.yml</code> è¿™ä¸ªæ–‡ä»¶ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥åœ¨ playbook ä¸­å¼•å…¥è¿™ä¸ª roleï¼š</p>

<pre><code class="language-yaml">---
- hosts: webservers
  roles:
     - common
     - webservers
</code></pre>

<p>role å’Œ role ä¹‹é—´å¯ä»¥è®¾ç½®ä¾èµ–å…³ç³»ï¼Œé€šè¿‡ä¾èµ–æˆ‘ä»¬å¯ä»¥éšå¼çš„æ‰§è¡ŒæŸäº› roleã€‚è§’è‰²ä¾èµ–éœ€è¦å®šä¹‰åœ¨ <code>meta/main.yml</code> æ–‡ä»¶ä¸­ï¼š</p>

<pre><code class="language-yaml">---
dependencies:
  - { role: common, some_parameter: 3 }
  - { role: apache, port: 80 }
  - { role: postgres, dbname: blarg, other_parameter: 12 }
</code></pre>

<blockquote>
<p>å½“ä¸€ä¸ª playbook åŒ…å«å¤šä¸ª roleï¼Œå¹¶ä¸” role ä¾èµ–äº†å…±åŒçš„ role æ—¶ï¼Œå¯èƒ½ä¼šæœ‰é‡å¤æ‰§è¡Œçš„æƒ…å†µã€‚ansible æœ‰ä¸€äº›æœºåˆ¶é¿å…é‡å¤æ— æ„ä¹‰çš„æ‰§è¡Œï¼Œä½†æ˜¯è¯¥è§„åˆ™ä¸æ˜¯å¾ˆå®¹æ˜“ç›´è§‚ç†è§£ã€‚</p>
</blockquote>

<h2 id="toc_5">å˜é‡</h2>

<h3 id="toc_6"><strong>å˜é‡çš„å®šä¹‰</strong></h3>

<p><strong>Inventory File</strong></p>

<pre><code>[all:vars]
foo1=bar
foo2=bar2

[group1]
host1
host2

[group1:vars]
foo3=bar3
</code></pre>

<p><strong>PlayBook</strong></p>

<pre><code class="language-yaml">---
- hosts: all
  vars:
    http_port: 80
  vars_prompt:
    - name: service_name
      prompt: &quot;Which service do you want to remove?&quot;
      private: no
  vars_files:
    - /vars/external_vars.yml
</code></pre>

<p><strong>Role</strong></p>

<p>æœ‰äº›å˜é‡åªç”¨äºå½“å‰ roleï¼Œå¯èƒ½ä¼šå®šä¹‰åœ¨ role å½“ä¸­ã€‚ä¸€èˆ¬ä½äº <code>defaults/mian.yml</code> æˆ–è€… <code>vars/</code> ç›®å½•ä¸‹ã€‚</p>

<p>å…·ä½“çš„ä½¿ç”¨å‚è§ï¼š<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html">https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html</a></p>

<p><strong>Ansible é¢„å®šä¹‰</strong></p>

<p>éƒ¨åˆ†å˜é‡æ˜¯ Ansible è‡ªå·±å®šä¹‰çš„å˜é‡ï¼Œæ¯”å¦‚æˆ‘ä»¬è¦è·å–æœºå™¨çš„ hostnameï¼š</p>

<pre><code class="language-bash">{{ ansible_facts[&#39;nodename&#39;] }}
</code></pre>

<p>è¿™éƒ¨åˆ†é¢„å®šä¹‰å˜é‡éå¸¸å¤šï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢å‘½ä»¤æŸ¥çœ‹ï¼š</p>

<pre><code class="language-bash">$ ansible hostname -m setup
{
    &quot;ansible_all_ipv4_addresses&quot;: [
        &quot;REDACTED IP ADDRESS&quot;
    ],
    &quot;ansible_all_ipv6_addresses&quot;: [
        &quot;REDACTED IPV6 ADDRESS&quot;
    ],
    &quot;ansible_apparmor&quot;: {
        &quot;status&quot;: &quot;disabled&quot;
    },
    &quot;ansible_architecture&quot;: &quot;x86_64&quot;,
    &quot;ansible_bios_date&quot;: &quot;11/28/2013&quot;
        ......
}
</code></pre>

<p><strong>Command Line</strong></p>

<pre><code class="language-bash">ansible-playbook site.yml --extra-vars=&#39;{&quot;foo&quot;: &quot;bar&quot;}&#39;
</code></pre>

<p><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html">https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html</a></p>

<h3 id="toc_7">å˜é‡çš„ä½œç”¨åŸŸ</h3>

<p>ansible çš„å˜é‡ä½œç”¨åŸŸä¸»è¦æœ‰ 3 ç§ï¼š</p>

<ul>
<li>Globalï¼šansible é…ç½®æ–‡ä»¶ï¼Œç¯å¢ƒå˜é‡ï¼Œå‘½ä»¤è¡Œ</li>
<li>Playï¼šplaybook vars, vars_prompt, vars_files; role defaults, vars</li>
<li>Host: Inventory ä¸­å®šä¹‰çš„çš„ host vars; facts</li>
</ul>

<h3 id="toc_8">å˜é‡ä½¿ç”¨</h3>

<p>ansible å…è®¸ä½ åœ¨å„å¤„é€šè¿‡ jinja2 çš„è¯­æ³•ä½¿ç”¨å˜é‡ã€‚jinja2 æ˜¯ä¸€ä¸ªç”¨ Python å¼€å‘çš„æ¨¡ç‰ˆå¼•æ“ï¼Œæœ¬èº«å¹¶ä¸å¤æ‚ï¼Œæ ¸å¿ƒä¸œè¥¿å°± 3 ä¸ªï¼šå˜é‡çš„è¾“å‡ºï¼Œæ§åˆ¶æµï¼Œfilter</p>

<p>ä¸¤ä¸ªå¤§æ‹¬å·åŒ…èµ·æ¥è¡¨ç¤ºè¾“å‡ºå˜é‡ï¼š</p>

<pre><code>I&#39;m {{ name }}
</code></pre>

<p>å˜é‡è¾“å‡ºæ—¶å¯ä»¥ç”¨è¿‡ filter æ§åˆ¶æ ¼å¼ï¼Œç±»ä¼¼ bash é‡Œçš„ pipelineã€‚filter æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª Python çš„å‡½æ•°ï¼Œæœ‰ä¸€ä¸ªå…¥å‚å’Œä¸€ä¸ªè¿”å›ç»“æœï¼š</p>

<pre><code>I&#39;m {{ name | trim | title }}
</code></pre>

<p>æ§åˆ¶æµéœ€è¦åŒºåˆ«äºè¾“å‡ºï¼Œç”¨ <code>{% %}</code> è¡¨ç¤ºã€‚æ¯”å¦‚ä¸€ä¸ª for å¾ªç¯</p>

<pre><code>{% for name in names %}
I&#39;m {{ name | title }}
{% endfor %}
</code></pre>

<p>æ¡ä»¶åˆ¤æ–­</p>

<pre><code>{% for name in names %}
{% if ignore_case %}
I&#39;m {{ name | lower }}
{% else %}
I&#39;m {{ name }}
{% endif %}
{% endif %}
</code></pre>

<p>ä¸Šé¢å°±æ˜¯ jinja2 çš„ä»‹ç»ï¼Œæ›´å¤šç»†èŠ‚éœ€è¦å»çœ‹æ–‡æ¡£ã€‚</p>

<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ Ansible ä¸­å¦‚æœä½ è¦ä½¿ç”¨ jinja2 çš„è¯­æ³•å»å¼•ç”¨ä¸€ä¸ªå˜é‡ï¼Œå¿…é¡»ç”¨åŒå¼•å·å†…ä½¿ç”¨ã€‚</p>

<pre><code class="language-yaml">- hosts: all
  vars:
    deploy_path: &quot;{{ home_dir }}/apps&quot;
</code></pre>

<p>æ¯”å¦‚æˆ‘ä»¬æƒ³æ ¹æ®å„ç§ä¸Šä¸‹æ–‡ç”Ÿæˆ nginx çš„é…ç½®æ–‡ä»¶ï¼Œå¯ä»¥é€šè¿‡ template å‘½ä»¤æ¥æ¸²æŸ“ã€‚é¦–å…ˆå®šä¸€ä¸ªæ¨¡ç‰ˆæ–‡ä»¶ <code>nginx.conf.j2</code></p>

<pre><code>server {
  server_name {{ server_name }};
  listen 80;
  
  location / {
    try_files $uri $uri/ /index.html;
  }
}
</code></pre>

<p>æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªé…ç½®æ–‡ä»¶å¯ä»¥è¦†ç›–é»˜è®¤çš„ nginx é…ç½®ï¼š</p>

<pre><code class="language-yaml">- hosts: nginx
  vars:
    server_name: gio.com
    nginx_user: nginx
    nginx_group: &quot;{{ nginx_user }}&quot;
  tasks:
    - name: generate nginx config file
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/nginx.conf
        owner: &quot;{{ nginx_user }}&quot;
        group: &quot;{{ nginx_group }}&quot;
      become: yes
</code></pre>

<h2 id="toc_9">æœ€ä½³å®è·µ</h2>

<h3 id="toc_10">ä¿æŒæ“ä½œçš„å¹‚ç­‰</h3>

<p>shell è„šæœ¬åœ¨æ‰§è¡Œæ—¶ï¼Œå¾ˆå¤šå‘½ä»¤çš„æ‰§è¡Œç»“æœä¸æ˜¯ç¡®å®šçš„ã€‚å¾ˆå¤šæ—¶å€™æˆ‘ä»¬æ— æ³•é¿å…çš„éœ€è¦åå¤é‡è¯•æŸäº›è„šæœ¬ï¼š</p>

<ul>
<li>è„šæœ¬è‡ªèº«æœ‰ bugï¼Œä¿®å®Œä»¥åéœ€è¦é‡è¯•</li>
<li>æœºå™¨çŠ¶æ€ä¸ç¡®å®šã€‚æ¯”å¦‚è„šæœ¬æ‰§è¡Œè¿‡ç¨‹ä¸­æœºå™¨é‡å¯äº†ï¼›å…å¯† sudo å¿˜è®°é…ç½®ç»“æœæ‰§è¡Œåˆ°æŸä¸ªéœ€è¦ sudo çš„ task æ—¶è·ªäº†ã€‚</li>
<li>å‘½ä»¤æœ¬èº«æ‰§è¡Œç»“æœå°±æ˜¯ä¸ç¡®å®šçš„ï¼Œæ¯”å¦‚é€šè¿‡ systemd å¯åŠ¨ä¸€ä¸ªè¿›ç¨‹ï¼Œsystemctl start å‘½ä»¤è¿”å›æˆåŠŸå¹¶ä¸ä»£è¡¨çœŸçš„å¯åŠ¨æˆåŠŸäº†ã€‚</li>
</ul>

<p>ansible çš„å†™æ³•éƒ½æ˜¯å£°æ˜å¼è€Œä¸æ˜¯å‘½ä»¤å¼ã€‚å‘½ä»¤æè¿°è¿‡ç¨‹ï¼Œå£°æ˜å¼æè¿°æ„å›¾ã€‚æ˜ç¡®çš„æ„å›¾å¯ä»¥è®© ansible å¯ä»¥æ›´å¥½çš„å¸®ä½ å†³å®šæ˜¯å¦è¦é‡è¯•æŸä¸ªä»»åŠ¡ï¼Œå®‰å…¨çš„éšè—ç»†èŠ‚ã€‚æ¯”å¦‚æˆ‘ä»¬åˆ é™¤æŸä¸ªæ–‡ä»¶ï¼Œå‘½ä»¤å¼æè¿°è¿™æ ·çš„ï¼š</p>

<pre><code class="language-yaml">- name: delete file
  command: rm /tmp/xxx
</code></pre>

<p>ä½†æ˜¯å½“æˆ‘ä»¬é‡å¤è·‘è¿™ä¸ª task æ—¶ï¼Œå·²ç»è¢«åˆ é™¤æ–‡ä»¶æ— æ³•å†æ¬¡è¢«åˆ é™¤ï¼Œéœ€è¦åœ¨æ¯æ¬¡åˆ é™¤å‰æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²ç»è¢«åˆ é™¤ã€‚ä½†æ˜¯ç”¨å£°æ˜å¼çš„å†™æ³•å°±å¾ˆå®¹æ˜“å®ç°ï¼š</p>

<pre><code class="language-yaml">- name: delete file
  file:
    src: /tmp/xxx
    state: absent
</code></pre>

<p>ç¼–å†™ ansible è„šæœ¬æ—¶ï¼Œè¦å§‹ç»ˆè®°å¾—ä¸€ä»¶äº‹ï¼šä¸è¦æƒ³ç€ä½ è¦åšä»€ä¹ˆæ“ä½œï¼Œè€Œæ˜¯æè¿°ä½ æœŸæœ›æŸä¸ªå¯¹è±¡çš„çŠ¶æ€æ˜¯æ€ä¹ˆæ ·çš„ã€‚</p>

<h3 id="toc_11">è°¨æ…å¤„ç†é root ç”¨æˆ·è¿è¡Œæ—¶çš„é€»è¾‘</h3>

<p>ansible çš„ task æœ‰ä¸¤ä¸ªå±æ€§ <code>become</code> å’Œ <code>become_user</code> ï¼Œåˆ†åˆ«ä»£è¡¨æ˜¯å¦è¦ä½¿ç”¨ sudo ä»¥åŠ sudo çš„ç”¨æˆ·ã€‚æ¯”å¦‚åˆ›å»ºä¸€ä¸ªç›®å½•å¹¶æŒ‡å®šç›®å½•çš„ owner å’Œ group</p>

<pre><code class="language-yaml">- name: create dir
  file:
    path: /etc/foo
    state: directory
    owner: foo
    group: foo
</code></pre>

<p>å¦‚æœæˆ‘ä»¬ä»¥ root ç”¨æˆ·çš„èº«ä»½æ‰§è¡Œ ansible è„šæœ¬ï¼Œä¸Šé¢çš„è„šæœ¬æ²¡æœ‰ä»»ä½•é—®é¢˜ã€‚ä½†æ˜¯å¦‚æœæ˜¯ä¸€ä¸ªæœ‰ sudo æƒé™çš„æ™®é€šç”¨æˆ·ï¼Œå¦‚æœæ²¡æœ‰æ˜¾å¼ä½¿ç”¨ sudo çš„è¯ï¼Œæ²¡æœ‰æƒé™åœ¨ <code>/etc</code> ç›®å½•ä¸‹åˆ›å»ºä»»ä½•ä¸œè¥¿ã€‚è¿™æ˜¯æ—¶å€™å°±éœ€è¦ä½¿ç”¨ <code>become</code></p>

<pre><code class="language-yaml">- name: create dir
  file:
    path: /etc/foo
    state: directory
    owner: foo
    group: foo
  become: yes
</code></pre>

<h3 id="toc_12">æµ‹è¯•è„šæœ¬</h3>

<p>æ£€æŸ¥è¯­æ³•ï¼š</p>

<pre><code class="language-yaml">ansible-playbook --syntax-check &lt;playbook&gt;
</code></pre>

<p>Dry-run:</p>

<pre><code class="language-yaml">ansible-playbook --check &lt;playbook&gt;
</code></pre>

<p>çœŸå®æ‰§è¡Œè„šæœ¬ï¼š</p>

<p>ç”±äºæµ‹è¯•å¯èƒ½éœ€è¦åå¤æ‰§è¡Œï¼Œæ¯æ¬¡éƒ½ç”³è¯·æœåŠ¡å™¨æ˜¾ç„¶ä¸ç°å®ï¼Œæ¨èæœ¬åœ°ç”¨ VirtualBox + Vagrant æ¥è¿›è¡Œæµ‹è¯•ã€‚</p>

<p>é¦–å…ˆå®šä¹‰ Vargrantfileï¼Œæ¥åˆ›å»º 3 ä¸ªè™šæ‹Ÿæœºï¼Œhostname æ˜¯ hadoop[1-3]</p>

<pre><code class="language-yaml">$ cat Vagrantfile                                                                                                                                                    
# -*- mode: ruby -*-
# vi: set ft=ruby :

# All Vagrant configuration is done below. The &quot;2&quot; in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don&#39;t change it unless you know what
# you&#39;re doing.
Vagrant.configure(&quot;2&quot;) do |config|
  config.vm.define &#39;hadoop01&#39; do |hadoop01|
    hadoop01.vm.box = &#39;centos/7&#39;
    hadoop01.vm.hostname = &#39;hadoop01&#39;
    hadoop01.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8000
    hadoop01.vm.network :private_network, :ip =&gt; &#39;192.168.10.192&#39;
    hadoop01.vm.provision :hosts, :sync_hosts =&gt; true
    hadoop01.vm.provision :hosts, :add_localhost_hostnames =&gt; false
    hadoop01.vm.provider :virtualbox do |v|
      v.customize [&quot;modifyvm&quot;, :id, &quot;--natdnshostresolver1&quot;, &quot;on&quot;]
      v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, 2048]
      v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;hadoop01&quot;]
    end
  end

  config.vm.define &#39;hadoop02&#39; do |hadoop02|
    hadoop02.vm.box = &#39;centos/7&#39;
    hadoop02.vm.hostname = &#39;hadoop02&#39;
    hadoop02.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8001
    hadoop02.vm.network :private_network, :ip =&gt; &#39;192.168.10.193&#39;
    hadoop02.vm.provision :hosts, :sync_hosts =&gt; true
    hadoop02.vm.provision :hosts, :add_localhost_hostnames =&gt; false
    hadoop02.vm.provider :virtualbox do |v|
      v.customize [&quot;modifyvm&quot;, :id, &quot;--natdnshostresolver1&quot;, &quot;on&quot;]
      v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, 2048]
      v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;hadoop02&quot;]
    end
  end

  config.vm.define &#39;hadoop03&#39; do |hadoop03|
    hadoop03.vm.box = &#39;centos/7&#39;
    hadoop03.vm.hostname = &#39;hadoop03&#39;
    hadoop03.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8002
    hadoop03.vm.network :private_network, :ip =&gt; &#39;192.168.10.194&#39;
    hadoop03.vm.provision :hosts, :sync_hosts =&gt; true
    hadoop03.vm.provision :hosts, :add_localhost_hostnames =&gt; false
    hadoop03.vm.provider :virtualbox do |v|
      v.customize [&quot;modifyvm&quot;, :id, &quot;--natdnshostresolver1&quot;, &quot;on&quot;]
      v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, 2048]
      v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;hadoop03&quot;]
    end
  end
end
</code></pre>

<p>å¯åŠ¨æœåŠ¡å™¨å¹¶é…ç½® ssh</p>

<pre><code class="language-yaml">$ vagrant up

$ vagrat ssh-config
</code></pre>

<p>åˆ›å»ºä¸€ä¸ªç”¨äºæµ‹è¯•çš„ inventory fileï¼Œç„¶åæ‰§è¡Œ playbookï¼š</p>

<pre><code class="language-yaml">ansible-playbook &lt;playbook&gt; -i &lt;inventory_file&gt;
</code></pre>

<p>å•å…ƒæµ‹è¯•ï¼š</p>

<p>ansible çš„å•å…ƒæµ‹è¯•æ¯”è¾ƒæ¥è¿‘é›†æˆæµ‹è¯•ã€‚æœ‰ç¬¬ä¸€ä¸ªç¬¬ä¸‰æ–¹çš„æ¡†æ¶å¯ä»¥æ”¯æŒï¼š</p>

<p><a href="https://molecule.readthedocs.io/en/latest/">https://molecule.readthedocs.io/en/latest/</a></p>

<p>ç»†èŠ‚æ¯”è¾ƒå¤šè¿™é‡Œä¸å•ç‹¬ä»‹ç»ï¼Œæ‰§è¡Œä¹Ÿéœ€è¦ä¾èµ– docker æˆ–è€… vagrant</p>

<h2 id="toc_13">Reference</h2>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">https://en.wikipedia.org/wiki/Infrastructure_as_code</a></li>
<li><a href="https://ansible-tran.readthedocs.io/en/latest/docs/intro.html">https://ansible-tran.readthedocs.io/en/latest/docs/intro.html</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-09-10T11:45:44+08:00" itemprop="datePublished">2019/9/10</time>
			</div>
			
			 
			
		</div>
		<h1 class="title" itemprop="name"><a href="15680871440612.html" itemprop="url">
		Hive é”æœºåˆ¶</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">èƒŒæ™¯</h2>

<p>Hive é”æœºåˆ¶æ˜¯ä¸ºäº†è®© Hive æ”¯æŒå¹¶å‘è¯»å†™è€Œè®¾è®¡çš„ featureï¼Œå¦å¤–è¦è§£å†³å¹¶å‘è¯»å†™çš„æƒ…å†µä¸‹â€è„è¯»â€œ ï¼ˆRead uncommitedï¼‰çš„é—®é¢˜ã€‚è„è¯»çš„é—®é¢˜æœ¬èº«é€šè¿‡å®ç°äº†åŸå­çš„ reader/writer å·²ç»å¾—åˆ°è§£å†³ï¼ˆ<a href="https://issues.apache.org/jira/browse/HIVE-829">https://issues.apache.org/jira/browse/HIVE-829</a>ï¼‰å’Œé”æœºåˆ¶å¹¶ä¸ç»‘å®šã€‚</p>

<h2 id="toc_1">é”æœºåˆ¶</h2>

<p>Hive å†…éƒ¨å®šä¹‰äº†ä¸¤ç§ç±»å‹çš„é”ï¼š</p>

<ul>
<li>å…±äº«é”(Share)</li>
<li>äº’æ–¥é”(Exclusive)</li>
</ul>

<p>ä¸åŒé”ä¹‹é—´çš„å…¼å®¹æ€§å…¥ä¸‹é¢è¡¨æ ¼ï¼š</p>

<table>
<thead>
<tr>
<th>Lock Compatibility</th>
<th>Existing Lockï¼ˆSï¼‰</th>
<th>Existing Lockï¼ˆXï¼‰</th>
</tr>
</thead>

<tbody>
<tr>
<td>RequestedÂ Lockï¼ˆSï¼‰</td>
<td>True</td>
<td>False</td>
</tr>
<tr>
<td>RequestedÂ Lockï¼ˆXï¼‰</td>
<td>False</td>
<td>False</td>
</tr>
</tbody>
</table>

<p>é”çš„åŸºæœ¬æœºåˆ¶æ˜¯ï¼š</p>

<ul>
<li>å…ƒä¿¡æ¯å’Œæ•°æ®çš„å˜æ›´éœ€è¦äº’æ–¥é”</li>
<li>æ•°æ®çš„è¯»å–éœ€è¦å…±äº«é”</li>
</ul>

<p>æ ¹æ®è¿™ä¸ªæœºåˆ¶ï¼ŒHive çš„ä¸€äº›åœºæ™¯æ“ä½œå¯¹åº”çš„é”çº§åˆ«å¦‚ä¸‹ï¼š</p>

<table>
<thead>
<tr>
<th>Hive command</th>
<th>Locks Acquired</th>
</tr>
</thead>

<tbody>
<tr>
<td>select .. T1 partition P1</td>
<td>S on T1, T1.P1</td>
</tr>
<tr>
<td>insert into T2(partition P2) select .. T1 partition P1</td>
<td>S on T2, T1, T1.P1 and X on T2.P2</td>
</tr>
<tr>
<td>insert into T2(partition P.Q) select .. T1 partition P1</td>
<td>S on T2, T2.P, T1, T1.P1 and X on T2.P.Q</td>
</tr>
<tr>
<td>alter table T1 rename T2</td>
<td>X on T1</td>
</tr>
<tr>
<td>alter table T1 add cols</td>
<td>X on T1</td>
</tr>
<tr>
<td>alter table T1 replace cols</td>
<td>X on T1</td>
</tr>
<tr>
<td>alter table T1 change cols</td>
<td>X on T1</td>
</tr>
<tr>
<td>alter table T1Â concatenate</td>
<td>X on T1</td>
</tr>
<tr>
<td>alter table T1 add partition P1</td>
<td>S on T1, X on T1.P1</td>
</tr>
<tr>
<td>alter table T1 drop partition P1</td>
<td>S on T1, X on T1.P1</td>
</tr>
<tr>
<td>alter table T1 touch partition P1</td>
<td>S on T1, X on T1.P1</td>
</tr>
<tr>
<td>alter table T1 set serdeproperties</td>
<td>S on T1</td>
</tr>
<tr>
<td>alter table T1 set serializer</td>
<td>S on T1</td>
</tr>
<tr>
<td>alter table T1 set file format</td>
<td>S on T1</td>
</tr>
<tr>
<td>alter table T1 set tblproperties</td>
<td>X on T1</td>
</tr>
<tr>
<td>alter table T1 partition P1 concatenate</td>
<td>X on T1.P1</td>
</tr>
<tr>
<td>drop table T1</td>
<td>X on T1</td>
</tr>
</tbody>
</table>

<p>Hive é”åœ¨ zookeeper ä¸Šä¼šå¯¹åº”Â ephemeral çš„èŠ‚ç‚¹ï¼Œé¿å…é‡Šæ”¾é”å¤±è´¥å¯¼è‡´æ­»é”</p>

<h2 id="toc_2">è°ƒè¯•é”ğŸ”</h2>

<p>å¯ä»¥é€šè¿‡ä¸‹é¢å‘½ä»¤æŸ¥çœ‹æŸä¸ªè¡¨æˆ–è€…åˆ†åŒºçš„é”</p>

<ul>
<li>SHOW LOCKS <TABLE_NAME>;</li>
<li>SHOW LOCKS <TABLE_NAME> EXTENDED;</li>
<li>SHOW LOCKS <TABLE_NAME> PARTITION (<PARTITION_DESC>);</li>
<li>SHOW LOCKS <TABLE_NAME> PARTITION (<PARTITION_DESC>) EXTENDED;</li>
</ul>

<p>See alsoÂ <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain#LanguageManualExplain-TheLOCKSClause">EXPLAIN LOCKS</a>.</p>

<h2 id="toc_3">å…³é—­é”æœºåˆ¶</h2>

<p>å¯ä»¥é€šè¿‡è®¾ç½®Â <code>hive.support.concurrency=fasle</code> æ¥è§£å†³</p>

<p>å…³é—­é”æœºåˆ¶ä¼šé€ æˆä¸‹é¢å½±å“ï¼š</p>

<ul>
<li>å¹¶å‘è¯»å†™åŒä¸€ä»½æ•°æ®æ—¶ï¼Œè¯»æ“ä½œå¯èƒ½ä¼šéšæœºå¤±è´¥</li>
<li>å¹¶å‘å†™æ“ä½œçš„ç»“æœåœ¨éšæœºå‡ºç°ï¼Œåå®Œæˆçš„ä»»åŠ¡è¦†ç›–ä¹‹å‰å®Œæˆä»»åŠ¡çš„ç»“æœ</li>
<li>SHOW LOCKSï¼Œ UNLOCK TABLE ä¼šæŠ¥é”™</li>
</ul>

<h2 id="toc_4">HiveLockManager çš„å®ç°</h2>

<p>åœ¨å…³é—­ Hive é”çš„è¿‡ç¨‹ä¸­ï¼Œå‘ç°ç²—æš´çš„ç¦ç”¨ concurrency ä¼šå¯¼è‡´ UNLOCK TABLE è¯­æ³•æŠ¥é”™ã€‚ä¸€äº›é—ç•™ç³»ç»Ÿå·²ç»ä¾èµ–è¿™ä¸ªè¯­æ³•æ¥ç¡®ä¿è‡ªèº«ä»»åŠ¡ä¸è¢«é˜»å¡ï¼Œè¿™æ ·çš„ä¿®æ”¹ä¼šå¯¼è‡´è¿™äº›ç¨‹åºå‡ºç°é—®é¢˜ã€‚äºæ˜¯è½¬è€Œç ”ç©¶æœ‰æ²¡æœ‰å…¶ä»–ç®€å•é”çš„å®ç°å¯ä»¥è¾¾åˆ°ç±»ä¼¼çš„æ•ˆæœã€‚ç²—çœ‹ Hive çš„ä»£ç æ‰¾åˆ°è¿™ 3  ç§å®ç°ï¼š</p>

<ul>
<li>DbLockManager é…åˆÂ DbTxnManager ç”¨äºåœ¨ Hive ä¸­å®ç°äº‹åŠ¡ï¼Œä¸èƒ½å•ç‹¬ä½¿ç”¨</li>
<li>EmbeddedLockManager HiveServer çº§åˆ«åŸºäºå†…å­˜å®ç°çš„é”</li>
<li>ZooKeeperHiveLockManager é»˜è®¤çš„ LockManager å®ç°ï¼ŒåŸºäº zookeeper å®ç°çš„åˆ†å¸ƒå¼åè°ƒé”</li>
</ul>

<h2 id="toc_5">Hive Zookeeper é”æ³„éœ²é—®é¢˜</h2>

<p>åœ¨ cancel Hive æŸ¥è¯¢æ—¶ï¼Œæœ‰æ¦‚ç‡å‘ç”Ÿ Zookeeper é”é‡Šæ”¾å¤±è´¥çš„é—®é¢˜ã€‚å› ä¸º Hive çš„é”åœ¨Zookeeper æ˜¯æŒä¹…èŠ‚ç‚¹ï¼Œç´¯è®¡çš„é”é‡Šæ”¾å¤±è´¥å¯èƒ½é€ æˆ Zookeeper çš„ Node æ•°é‡è¿‡å¤šï¼Œå½±å“ Zookeeper çš„æ€§èƒ½ã€‚ç¤¾åŒºæœ‰å¯¹åº”çš„ ISSUEï¼Œè¯¥é—®é¢˜åœ¨ 2.3.0 ç‰ˆæœ¬æ‰è¢« FIX: <a href="https://issues.apache.org/jira/browse/HIVE-15997">https://issues.apache.org/jira/browse/HIVE-15997</a></p>

<p>HiveServer ä¸Šå¯ä»¥å‘ç°ç±»ä¼¼æ—¥å¿—ï¼Œå°±æ˜¯é”é‡Šæ”¾å¤±è´¥çš„æ ‡å¿—ï¼š</p>

<pre><code>2019-03-06T07:41:56,556 ERROR [HiveServer2-Background-Pool: Thread-45399] ZooKeeperHiveLockManager: Failed to release ZooKeeper lock:
java.lang.InterruptedException
        at java.lang.Object.wait(Native Method) ~[?:1.8.0_45]
        at java.lang.Object.wait(Object.java:502) ~[?:1.8.0_45]
        at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342) ~[zookeeper-3.4.5-cdh5.5.0.jar:3.4.5-cdh5.5.0--1]
        at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:871) ~[zookeeper-3.4.5-cdh5.5.0.jar:3.4.5-cdh5.5.0--1]
        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[curator-framework-2.6.0.jar:?]
        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[curator-framework-2.6.0.jar:?]
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[curator-client-2.6.0.jar:?]
        at org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[curator-framework-2.6.0.jar:?]
        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[curator-framework-2.6.0.jar:?]
        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[curator-framework-2.6.0.jar:?]
        at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.unlockPrimitive(ZooKeeperHiveLockManager.java:474) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.unlockWithRetry(ZooKeeperHiveLockManager.java:452) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.unlock(ZooKeeperHiveLockManager.java:440) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.releaseLocks(ZooKeeperHiveLockManager.java:222) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager.releaseLocks(DummyTxnManager.java:188) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.Driver.releaseLocksAndCommitOrRollback(Driver.java:1136) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.Driver.rollback(Driver.java:1516) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1456) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1171) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1166) [hive-exec-2.1.1.jar:2.1.1]
        at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:242) [hive-service-2.1.1.jar:2.1.1]
        at org.apache.hive.service.cli.operation.SQLOperation.access$800(SQLOperation.java:91) [hive-service-2.1.1.jar:2.1.1]
        at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:334) [hive-service-2.1.1.jar:2.1.1]
        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_45]
        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_45]
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671) [hadoop-common-2.6.0-cdh5.5.0.jar:?]
        at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:347) [hive-service-2.1.1.jar:2.1.1]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_45]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_45]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_45]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_45]
        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]
</code></pre>

<p>é”æ³„éœ²é™¤äº†ä¿®å¤è¿™ä¸ª ISSUE ä»¥å¤–æ¯”è¾ƒéš¾å¤„ç†ã€‚åœ¨å…¬å¸ä¸­ï¼Œå¦‚æœæœ‰æˆç†Ÿçš„è°ƒåº¦å™¨åè°ƒä»»åŠ¡çš„ä¾èµ–å…³ç³»ï¼Œé‚£ä¹ˆéå¸¸å»ºè®®ç¦ç”¨æ‰ Hive çš„é”æœºåˆ¶ã€‚åœ¨è¡¨æ•°é‡ä¼—å¤šï¼Œåˆ†åŒºä¼—å¤šçš„åœºæ™¯ä¸‹ï¼Œä½¿ç”¨ Zookeeper çš„ä»£ä»·ä¹Ÿæ˜¯éå¸¸é«˜çš„ã€‚</p>

<h2 id="toc_6">å‚è€ƒèµ„æ–™</h2>

<ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Locking">https://cwiki.apache.org/confluence/display/Hive/Locking</a></li>
<li><a href="https://issues.apache.org/jira/browse/HIVE-1293">https://issues.apache.org/jira/browse/HIVE-1293</a></li>
<li><a href="https://issues.apache.org/jira/browse/HIVE-15997">https://issues.apache.org/jira/browse/HIVE-15997</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2018-11-10T10:00:52+08:00" itemprop="datePublished">2018/11/10</time>
			</div>
			
			 
			
		</div>
		<h1 class="title" itemprop="name"><a href="15418152524286.html" itemprop="url">
		å¤§æ•°æ®å¹³å°çš„æ•°æ®åŒæ­¥æœåŠ¡å®è·µ</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">å¼•è¨€</h2>

<p>åœ¨å¤§æ•°æ®ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬å¾€å¾€æ— æ³•ç›´æ¥å¯¹åœ¨çº¿ç³»ç»Ÿä¸­çš„æ•°æ®ç›´æ¥è¿›è¡Œæ£€ç´¢å’Œè®¡ç®—ã€‚åœ¨çº¿ç³»ç»Ÿæ‰€ä½¿ç”¨å…³ç³»å‹æ•°æ®åº“ï¼Œç¼“å­˜å­˜å‚¨æ•°æ®çš„æ–¹å¼éƒ½éå¸¸ä¸åŒï¼Œå¾ˆå¤šç³»ç»Ÿä¸é€‚åˆ OLAP å¼çš„æŸ¥è¯¢ï¼Œä¹Ÿä¸å…è®¸ OLAP æŸ¥è¯¢å½±å“åˆ°åœ¨çº¿ä¸šåŠ¡çš„ç¨³å®šæ€§ã€‚ä»æ•°ä»“å»ºè®¾çš„è§’åº¦æ€è€ƒï¼Œç¨³å®šè§„èŒƒçš„æ•°ä»“å¿…å®šä¾èµ–äºç¨³å®šå’Œè§„èŒƒçš„æ•°æ®æºï¼Œæ•°æ®éœ€è¦ç»è¿‡é‡‡é›†åŠ å·¥åæ‰èƒ½çœŸæ­£è¢«æ•°ä»“æ‰€ä½¿ç”¨ã€‚æ¨åŠ¨æ•°æ®åŒæ­¥æœåŠ¡çš„å¹³å°åŒ–ï¼Œæ‰æœ‰å¯èƒ½ä»æºå¤´è§„èŒƒæ•°æ®çš„äº§å‡ºã€‚æ•°æ®åŒæ­¥æœåŠ¡ä¸åƒæ•°æ®æŒ–æ˜ä¸€æ ·å¯ä»¥ç›´æ¥äº§ç”Ÿä»·å€¼ï¼Œä½†å®ƒæ›´åƒæ˜¯è¿æ¥ä¸åŒå­˜å‚¨çš„é«˜é€Ÿå…¬è·¯ï¼Œå¥½çš„åŒæ­¥å·¥å…·å¯ä»¥å¾ˆå¤§ç¨‹åº¦ä¸Šæå‡æ•°æ®å¼€å‘çš„æ•ˆç‡ã€‚</p>

<p>æœ¬æ–‡ä¸»è¦ä»‹ç»çŸ¥ä¹åœ¨æ•°æ®åŒæ­¥è¿™æ–¹é¢çš„å»ºè®¾ï¼Œå·¥å…·é€‰å‹å’Œå¹³å°åŒ–çš„å®è·µã€‚</p>

<h2 id="toc_1">ä¸šåŠ¡åœºæ™¯åŠæ¶æ„</h2>

<p>åœ¨çº¿ä¸šåŠ¡çš„æ•°æ®åº“åœ¨çŸ¥ä¹å†…éƒ¨è¿˜æ˜¯ä»¥ MySQL å’Œ HBase ä¸ºä¸»ï¼Œæ‰€ä»¥æ•°æ®æºæ–¹é¢ä¸»è¦è€ƒè™‘ MySQL å’Œ Hive çš„äº’ç›¸åŒæ­¥ï¼Œåç»­å¯ä»¥æ”¯æŒ HBaseã€‚æ—©æœŸæ•°æ®åŒæ­¥ä½¿ç”¨ Oozie + Sqoop æ¥å®Œæˆï¼ŒåŸºæœ¬æ»¡è¶³ä¸šåŠ¡éœ€æ±‚ã€‚ä½†æ˜¯éšç€æ•°ä»“ä»»åŠ¡ä¸æ–­å˜å¤šï¼Œå‡ºç°äº†å¾ˆå¤šé‡å¤åŒæ­¥çš„ä¾‹å­ï¼Œå¯¹åŒæ­¥ä»»åŠ¡çš„è´Ÿè½½ç®¡ç†ä¹Ÿæ˜¯ç©ºç™½ã€‚å‡Œæ™¨åŒæ­¥æ•°æ®å¯¼è‡´ MySQL ä¸æ–­æŠ¥è­¦ï¼ŒDBA è‹¦ä¸å ªè¨€ã€‚å¯¹äºä¸šåŠ¡æ¥è¯´ï¼Œå“ªäº›è¡¨å·²ç»è¢«åŒæ­¥äº†ï¼Œå“ªäº›è¡¨è¿˜æ²¡æœ‰ä¹Ÿæ˜¯ä¸€ä¸ªé»‘ç›’å­ï¼Œä¾èµ–å…¶ä»–ä¸šåŠ¡æ–¹çš„æ•°æ®éƒ½åªèƒ½é å£å¤´çš„çº¦å®šã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œå†³å®šå¯¹æ•°æ®åŒæ­¥åšä¸€ä¸ªç»Ÿä¸€çš„å¹³å°ï¼Œç®€åŒ–åŒæ­¥ä»»åŠ¡çš„é…ç½®ï¼Œè°ƒåº¦å¹³è¡¡è´Ÿè½½ï¼Œç®¡ç†å…ƒä¿¡æ¯ç­‰ç­‰ã€‚</p>

<h2 id="toc_2">æŠ€æœ¯é€‰å‹</h2>

<p>æ•°æ®åŒæ­¥å·¥å…·å¸‚é¢ä¸Šæœ‰å¾ˆå¤šè§£å†³æ–¹æ¡ˆï¼Œé¢å‘æ‰¹çš„ä¸»è¦æœ‰ <a href="http://sqoop.apache.org/">Apache Sqoop</a> å’Œé˜¿é‡Œå¼€æºçš„ <a href="https://github.com/alibaba/DataX">DataX</a>ï¼Œä¸‹é¢ä¸»è¦å¯¹æ¯”è¿™ä¸¤ç§æ•°æ®åŒæ­¥å·¥å…·ã€‚</p>

<h5 id="toc_3">Sqoop</h5>

<p>Prosï¼š</p>

<ul>
<li>åŸºäº MapReduce å®ç°ï¼Œå®¹æ˜“å¹¶è¡Œå’Œåˆ©ç”¨ç°æœ‰é›†ç¾¤çš„è®¡ç®—èµ„æº</li>
<li>å’Œ Hive å…¼å®¹æ€§å¥½ï¼Œæ”¯æŒ Parquetï¼ŒORC ç­‰æ ¼å¼</li>
<li>æ”¯æŒè‡ªåŠ¨è¿ç§» Schema</li>
<li>ç¤¾åŒºå¼ºå¤§ï¼Œé‡åˆ°çš„é—®é¢˜å®¹æ˜“è§£å†³</li>
</ul>

<p>Consï¼š</p>

<ul>
<li>æ”¯æŒçš„æ•°æ®æºä¸ç®—å¤ªä¸°å¯Œï¼ˆæ¯”å¦‚ ESï¼‰ï¼Œæ‰©å±•éš¾åº¦å¤§</li>
<li>ä¸æ”¯æŒé™é€Ÿï¼Œå®¹æ˜“å¯¹ MySQL é€ æˆå‹åŠ›</li>
</ul>

<h5 id="toc_4">DataX</h5>

<p>Prosï¼š</p>

<ul>
<li>æ”¯æŒçš„æ•°æ®æºä¸°å¯Œå°¤å…¶æ˜¯æ”¯æŒä»éå…³ç³»å‹æ•°æ®åº“åˆ°å…³ç³»å‹æ•°æ®åº“çš„åŒæ­¥</li>
<li>æ”¯æŒé™é€Ÿ</li>
<li>æ‰©å±•æ–¹ä¾¿ï¼Œæ’ä»¶å¼€å‘éš¾åº¦ä½</li>
</ul>

<p>Consï¼š</p>

<ul>
<li>éœ€è¦é¢å¤–çš„è¿è¡Œèµ„æºï¼Œå½“ä»»åŠ¡æ¯”è¾ƒå¤šçš„æ—¶å€™è´¹æœºå™¨</li>
<li>æ²¡æœ‰åŸç”Ÿæ”¯æŒå¯¼å‡ºåˆ° Hiveï¼Œéœ€è¦åšå¾ˆå¤šé¢å¤–çš„å·¥ä½œæ‰èƒ½æ»¡è¶³éœ€æ±‚</li>
</ul>

<p>è€ƒè™‘åˆ°åŒæ­¥æœ¬èº«è¦æ¶ˆè€—ä¸å°‘çš„è®¡ç®—å’Œå¸¦å®½èµ„æºï¼ŒSqoop å¯ä»¥æ›´å¥½çš„åˆ©ç”¨ Hadoop é›†ç¾¤çš„èµ„æºï¼Œè€Œä¸”å’Œ Hive é€‚é…çš„æ›´å¥½ï¼Œæœ€ç»ˆé€‰æ‹©äº† Sqoop ä½œä¸ºæ•°æ®åŒæ­¥çš„å·¥å…·ã€‚</p>

<h2 id="toc_5">å¹³å°åŒ–åŠå®è·µ</h2>

<p>å¹³å°åŒ–çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªç›¸å¯¹é€šç”¨çš„æ•°æ®åŒæ­¥å¹³å°ï¼Œæ›´å¥½çš„æ”¯æŒæ–°ä¸šåŠ¡çš„æ¥å…¥ï¼Œå’Œå…¬å¸å†…éƒ¨çš„ç³»ç»Ÿé›†æˆï¼Œæ»¡è¶³ä¸šåŠ¡éœ€æ±‚ã€‚å¹³å°åˆæœŸè®¾è®¡çš„ç›®æ ‡æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š</p>

<ul>
<li>ç®€å•çš„ä»»åŠ¡é…ç½®ç•Œé¢ï¼Œæ–¹ä¾¿æ–°çš„ä»»åŠ¡æ¥å…¥</li>
<li>ç›‘æ§å’ŒæŠ¥è­¦</li>
<li>å±è”½ MySQL DDL é€ æˆçš„å½±å“</li>
<li>å¯æ‰©å±•æ–°æ•°æ®æº</li>
</ul>

<h3 id="toc_6">ç®€åŒ–ä»»åŠ¡æ¥å…¥</h3>

<p>å¹³å°ä¸åº”è¯¥è¦æ±‚æ¯ä¸ªç”¨æˆ·éƒ½ç†è§£åº•å±‚æ•°æ®åŒæ­¥çš„åŸç†ï¼Œå¯¹ç”¨æˆ·è€Œè¨€ï¼Œåº”è¯¥æ˜¯æè¿°æ•°æ®æº (Source) å’Œç›®æ ‡å­˜å‚¨(Sink)ï¼Œè¿˜æœ‰åŒæ­¥å‘¨æœŸç­‰é…ç½®ã€‚æ‰€æœ‰æä¾›çš„åŒæ­¥ä»»åŠ¡åº”è¯¥ç»è¿‡å®¡æ ¸ï¼Œé˜²æ­¢æœªç»è®¸å¯çš„æ•°æ®è¢«åŒæ­¥ï¼Œæˆ–è€…åŒæ­¥é…ç½®ä¸åˆç†ï¼Œå¢åŠ å¹³å°è´Ÿæ‹…ã€‚æœ€åæš´éœ²ç»™ç”¨æˆ·çš„ UI å¤§æ¦‚å¦‚ä¸‹å›¾ã€‚</p>

<p><img src="media/15418152524286/15421169494010.jpg" alt="15421169494010" style="width:600px;"/></p>

<h3 id="toc_7">å¢é‡åŒæ­¥</h3>

<p>å¯¹äºæ•°æ®é‡éå¸¸å¤§çš„æ•°æ®æºï¼Œå¦‚æœæ¯æ¬¡åŒæ­¥éƒ½æ˜¯å…¨é‡ï¼Œå¯¹äº MySQL çš„å‹åŠ›ä¼šç‰¹åˆ«å¤§ï¼ŒåŒæ­¥éœ€è¦çš„æ—¶é—´ä¹Ÿä¼šå¾ˆé•¿ã€‚å› æ­¤éœ€è¦ä¸€ç§å¯ä»¥æ¯æ¬¡åªåŒæ­¥æ–°å¢æ•°æ®çš„æœºåˆ¶ï¼Œå‡å°‘å¯¹äº MySQL ç«¯çš„å‹åŠ›ã€‚ä½†æ˜¯å¢é‡åŒæ­¥ä¸æ˜¯æ²¡æœ‰ä»£ä»·çš„ï¼Œå®ƒè¦æ±‚ä¸šåŠ¡åœ¨è®¾è®¡è¡¨ç»“æ„çš„æ—¶å€™ï¼Œæ»¡è¶³ä¸€äº›çº¦æŸï¼š</p>

<ul>
<li>ä¸šåŠ¡å¯¹æ•°æ®æ²¡æœ‰ç‰©ç†çš„åˆ é™¤æ“ä½œï¼Œè€Œæ˜¯é‡‡ç”¨ç±»ä¼¼æ ‡è®°åˆ é™¤çš„æœºåˆ¶</li>
<li>æ•°æ®æ²¡æœ‰ UPDATE ï¼ˆç±»ä¼¼æ—¥å¿—ï¼‰ æˆ–è€…æœ‰ UPDATE ä½†æ˜¯æä¾› updated_at æ¥æ ‡è®°æ¯ä¸€è¡Œæœ€åä¸€æ¬¡æ›´æ–°çš„æ—¶é—´</li>
</ul>

<p>å¯¹äºæ»¡è¶³ä¸Šé¢æ¡ä»¶ï¼Œæ•°æ®é‡æ¯”è¾ƒå¤§çš„è¡¨å°±å¯ä»¥é‡‡ç”¨å¢é‡åŒæ­¥çš„æ–¹å¼æ‹‰å–ã€‚å°æ•°æ®é‡çš„è¡¨ä¸éœ€è¦è€ƒè™‘å¢é‡åŒæ­¥ï¼Œå› ä¸ºæ•°æ®å’Œåˆå¹¶ä¹Ÿéœ€è¦æ—¶é—´ï¼Œå¦‚æœæ”¶ç›Šä¸å¤§å°±ä¸åº”è¯¥å¼•å…¥é¢å¤–çš„å¤æ‚æ€§ã€‚ä¸€ä¸ªç»éªŒå€¼æ˜¯è¡Œæ•° &lt;= 2000w çš„éƒ½å±äºæ•°æ®é‡æ¯”è¾ƒå°çš„è¡¨ï¼Œå…·ä½“è¿˜å–å†³äºå­˜å‚¨çš„æ•°æ®å†…å®¹ï¼ˆæ¯”å¦‚æœ‰å¾ˆå¤š Text ç±»å‹çš„å­—æ®µï¼‰ã€‚</p>

<h3 id="toc_8">å¤„ç† Schema å˜æ›´</h3>

<p>åšæ•°æ®åŒæ­¥æ°¸è¿œå›é¿ä¸æ‰çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ Schema çš„å˜æ›´ï¼Œå¯¹ MySQL æ¥è¯´ï¼ŒSchema å˜æ›´å°±æ˜¯æ•°æ®åº“çš„ DDL æ“ä½œã€‚æ•°æ®åŒæ­¥å¹³å°åº”è¯¥å°½å¯èƒ½å±è”½ MySQL DDL å¯¹åŒæ­¥ä»»åŠ¡çš„å½±å“ï¼Œå¹¶ä¸”å¯¹å…¼å®¹çš„å˜æ›´ï¼ŒåŠæ—¶å˜æ›´æ¨é€åˆ°ç›®æ ‡å­˜å‚¨ã€‚</p>

<p>æ•°æ®åŒæ­¥å¹³å°ä¼šå®šæ—¶çš„æ‰«ææ¯ä¸ªåŒæ­¥ä»»åŠ¡ä¸Šæ¸¸çš„æ•°æ®æºï¼Œä¿å­˜å½“å‰ Schema çš„å¿«ç…§ï¼Œå¦‚æœå‘ç° Schema å‘ç”Ÿå˜åŒ–ï¼Œå°±é€šçŸ¥ä¸‹æ¸¸åšå‡ºä¸€æ ·çš„å˜æ›´ã€‚ç»å¤§éƒ¨åˆ†çš„ DDL è¿˜æ˜¯å¢åŠ å­—æ®µï¼Œå¯¹äºè¿™ç§æƒ…å†µæ•°æ®åŒæ­¥å¹³å°å¯ä»¥å¾ˆå¥½å±è”½å˜æ›´å¯¹æ•°ä»“çš„å½±å“ã€‚å¯¹äºåˆ é™¤å­—æ®µçš„æ“ä½œåŸåˆ™ä¸Šç¦æ­¢çš„ï¼Œå¦‚æœä¸€å®šè¦åšï¼Œéœ€è¦èµ°å˜æ›´æµç¨‹ï¼Œé€šçŸ¥åˆ°ä¾èµ–è¯¥è¡¨çš„ä¸šåŠ¡æ–¹ï¼Œè¿›è¡Œ Schema åŒæ­¥çš„è°ƒæ•´ã€‚</p>

<h3 id="toc_9">å­˜å‚¨æ ¼å¼</h3>

<p>Hive é»˜è®¤çš„æ ¼å¼æ˜¯ Textfileï¼Œè¿™æ˜¯ä¸€ç§ç±»ä¼¼ CSV çš„å­˜å‚¨æ–¹å¼ï¼Œä½†æ˜¯å¯¹äº OLAP æŸ¥è¯¢æ¥è¯´æ€§èƒ½å¹¶ä¸å‹å¥½ã€‚é€šå¸¸æˆ‘ä»¬ä¼šé€‰æ‹©ä¸€äº›åˆ—å¼å­˜å‚¨æé«˜å­˜å‚¨å’Œæ£€ç´¢çš„æ•ˆç‡ã€‚Hive ä¸­æ¯”è¾ƒæˆç†Ÿçš„åˆ—å¼å­˜å‚¨æ ¼å¼æœ‰ Parquet å’Œ ORCã€‚è¿™ä¸¤ä¸ªå­˜å‚¨çš„æŸ¥è¯¢æ€§èƒ½ç›¸å·®ä¸å¤§ï¼Œä½†æ˜¯ ORC å’Œ Hive é›†æˆæ›´å¥½è€Œä¸”å¯¹äºéåµŒå¥—æ•°æ®ç»“æ„æŸ¥è¯¢æ€§èƒ½æ˜¯ä¼˜äº Parquet çš„ã€‚ä½†æ˜¯çŸ¥ä¹å†…éƒ¨å› ä¸ºä¹Ÿç”¨äº† Impalaï¼Œæ—©æœŸçš„ Impala ç‰ˆæœ¬ä¸æ”¯æŒ ORC æ ¼å¼çš„æ–‡ä»¶ï¼Œä¸ºäº†å…¼å®¹ Impala æœ€ç»ˆé€‰æ‹©äº† Parquet ä½œä¸ºé»˜è®¤çš„å­˜å‚¨æ ¼å¼ã€‚</p>

<p>å…³äºåˆ—å¼å­˜å‚¨çš„åŸç†å’Œ Benchmarkï¼Œå¯ä»¥å‚è€ƒè¿™ä¸ª <a href="https://www.slideshare.net/oom65/file-format-benchmarks-avro-json-orc-parquet">Slide</a></p>

<h3 id="toc_10">è´Ÿè½½ç®¡ç†</h3>

<p>å½“åŒæ­¥ä»»åŠ¡è¶Šæ¥è¶Šå¤šæ—¶ï¼Œå•çº¯çš„æŒ‰ç…§ä»»åŠ¡å¯åŠ¨æ—¶é—´æ¥è§¦å‘åŒæ­¥ä»»åŠ¡å·²ç»ä¸èƒ½æ»¡è¶³éœ€æ±‚ã€‚æ•°æ®åŒæ­¥åº”è¯¥ä¿è¯å¯¹äºçº¿ä¸Šä¸šåŠ¡æ²¡æœ‰å½±å“ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šé€Ÿåº¦è¶Šå¿«è¶Šå¥½ã€‚æœ¬è´¨ä¸Šæ˜¯è®© Sqoop å……åˆ†åˆ©ç”¨ MySQL èŠ‚ç‚¹çš„ iopsã€‚è¦é¿å…å¯¹çº¿ä¸ŠæœåŠ¡çš„å½±å“ï¼Œå¯¹äºéœ€è¦æ•°æ®åŒæ­¥çš„åº“å•ç‹¬å»ºç«‹ä¸€ä¸ªä»èŠ‚ç‚¹ï¼Œéš”ç¦»çº¿ä¸Šæµé‡ã€‚åˆæ¬¡ä¹‹å¤–ï¼Œéœ€è¦ä¸€ä¸ªè°ƒåº¦ç­–ç•¥æ¥å†³å®šä¸€ä¸ªä»»åŠ¡ä½•æ—¶æ‰§è¡Œã€‚ç”±äºä»»åŠ¡çš„æ€»æ•°é‡å¹¶ä¸å¤šï¼Œä½†æ˜¯æ¯ä¸ªä»»åŠ¡å¯èƒ½ä¼šæ‰§è¡Œéå¸¸é•¿çš„æ—¶é—´ï¼Œæœ€ç»ˆå†³å®šé‡‡ç”¨ä¸€ä¸ªä¸­å¤®å¼çš„è°ƒåº¦å™¨ï¼Œè°ƒåº¦å™¨çš„çŠ¶æ€éƒ½æŒä¹…åŒ–åœ¨æ•°æ®åº“ä¸­ï¼Œæ–¹ä¾¿é‡å¯æˆ–è€…æ•…éšœæ¢å¤ã€‚æœ€ç»ˆæ¶æ„å›¾å¦‚ä¸‹</p>

<p><img src="media/15418152524286/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%B0%83%E5%BA%A6%E5%99%A8.jpg" alt="æ•°æ®åŒæ­¥è°ƒåº¦å™¨" style="width:336px;"/></p>

<p>æœ€ç»ˆä»»åŠ¡çš„è°ƒåº¦æµç¨‹å¦‚ä¸‹ï¼š</p>

<ol>
<li>æ¯ä¸ª MySQL å®ä¾‹æ˜¯è°ƒåº¦å™¨çš„ä¸€ä¸ªé˜Ÿåˆ—ï¼Œæ ¹æ®åŒæ­¥çš„å…ƒä¿¡æ¯å†³å®šè¯¥ä»»åŠ¡å±äºå“ªä¸ªé˜Ÿåˆ—</li>
<li>æ ¹æ®è¦åŒæ­¥æ•°æ®é‡é¢„ä¼°èµ„æºæ¶ˆè€—ï¼Œå‘è°ƒåº¦å™¨ç”³è¯·èµ„æº</li>
<li>è°ƒåº¦å™¨å°†ä»»åŠ¡æäº¤åˆ°æ‰§è¡Œé˜Ÿåˆ—ï¼Œæ²¡æœ‰æ„å¤–çš„è¯ä¼šç«‹åˆ»å¼€å§‹æ‰§è¡Œ</li>
<li>Monitor å®šæ—¶å‘è°ƒåº¦å™¨æ±‡æŠ¥ MySQL èŠ‚ç‚¹çš„è´Ÿè½½ï¼Œå¦‚æœè´Ÿè½½è¿‡é«˜å°±åœæ­¢å‘è¯¥é˜Ÿåˆ—æäº¤æ–°çš„ä»»åŠ¡</li>
<li>ä»»åŠ¡ç»“æŸåä»è°ƒåº¦å™¨å½’è¿˜èµ„æº</li>
</ol>

<h3 id="toc_11">æ€§èƒ½ä¼˜åŒ–</h3>

<h5 id="toc_12">é’ˆå¯¹ä¸åŒçš„æ•°æ®æºé€‰æ‹©åˆé€‚çš„å¹¶å‘æ•°</h5>

<p>Sqoop æ˜¯åŸºäº MapReduce å®ç°çš„ï¼Œæäº¤ä»»åŠ¡å‰å…ˆä¼šç”Ÿæˆ MapReduce ä»£ç ï¼Œç„¶åæäº¤åˆ° Hadoop é›†ç¾¤ã€‚Job æ•´ä½“çš„å¹¶å‘åº¦å°±å–å†³äº Mapper çš„ä¸ªæ•°ã€‚Sqoop é»˜è®¤çš„å¹¶å‘æ•°æ˜¯ 4ï¼Œå¯¹äºæ•°æ®é‡æ¯”è¾ƒå¤§çš„è¡¨çš„åŒæ­¥æ˜¾ç„¶æ˜¯ä¸å¤Ÿçš„ï¼Œå¯¹äºæ•°æ®é‡æ¯”è¾ƒå°çš„ä»»åŠ¡åˆå¤ªå¤šäº†ï¼Œè¿™ä¸ªå‚æ•°ä¸€å®šè¦åœ¨è¿è¡Œæ—¶æ ¹æ®æ•°æ®æºçš„å…ƒä¿¡æ¯å»åŠ¨æ€å†³å®šã€‚</p>

<h5 id="toc_13">ä¼˜åŒ– <a href="https://community.hortonworks.com/questions/79556/what-is-distributed-cache-in-hadoop.html">Distributed Cache</a> é¿å…ä»»åŠ¡å¯åŠ¨å¯¹ HDFS çš„å‹åŠ›</h5>

<p>åœ¨å¹³å°ä¸Šçº¿åï¼Œéšç€ä»»åŠ¡è¶Šæ¥è¶Šå¤šï¼Œå‘ç°å¦‚æœ HDFS çš„æ€§èƒ½å‡ºç°æŠ–åŠ¨ï¼Œå¯¹åŒæ­¥ä»»åŠ¡æ•´ä½“çš„æ‰§è¡Œæ—¶é—´å½±å“éå¸¸å¤§ï¼Œå¯¼è‡´å¤œé—´çš„å¾ˆå¤šåç»§ä»»åŠ¡å—åˆ°å½±å“ã€‚å¼€å§‹æ¨æµ‹æ˜¯æ•°æ®å†™å…¥ HDFS æ€§èƒ½æ…¢å¯¼è‡´åŒæ­¥å‡ºç°å»¶æ—¶ï¼Œä½†æ˜¯ä»»åŠ¡å¤§å¤šæ•°ä¼šå¡åœ¨æäº¤é˜¶æ®µã€‚éšç€è¿›ä¸€æ­¥æ’æŸ¥ï¼Œå‘ç° MapReduce ä¸ºäº†è§£å†³ä¸åŒä½œä¸šä¾èµ–é—®é¢˜ï¼Œå¼•å…¥äº† Distributed Cache æœºåˆ¶å¯ä»¥å°† Job ä¾èµ–çš„ lib ä¸Šä¼ åˆ° HDFSï¼Œç„¶åå†å¯åŠ¨ä½œä¸šã€‚Sqoop ä¹Ÿä½¿ç”¨äº†ç±»ä¼¼çš„æœºåˆ¶ï¼Œä¼šä¾èµ– Hive çš„ç›¸å…³ libï¼Œè¿™äº›ä¾èµ–åŠ èµ·æ¥æœ‰å¥½å‡ åä¸ªæ–‡ä»¶ï¼Œæ€»å¤§å°æ¥è¿‘ 150MBï¼Œè™½ç„¶å¯¹äº HDFS æ¥è¯´æ˜¯å¾ˆå°æ•°å­—ï¼Œä½†æ˜¯å½“åŒæ­¥ä»»åŠ¡éå¸¸å¤šçš„æ—¶å€™ï¼Œé›†ç¾¤ä¸€ç‚¹ç‚¹çš„æ€§èƒ½æŠ–åŠ¨éƒ½ä¼šå¯¼è‡´è°ƒåº¦å™¨çš„ååå¤§å¹…åº¦ä¸‹é™ï¼Œæœ€ç»ˆåŒæ­¥çš„äº§å‡ºä¼šæœ‰ä¸¥é‡å»¶æ—¶ã€‚æœ€åçš„è§£å†³æ–¹æ³•æ˜¯å°† Sqoop å®‰è£…åˆ°é›†ç¾¤ä¸­ï¼Œç„¶åé€šè¿‡ Sqoop çš„å‚æ•° <code>--skip-distcache</code> é¿å…åœ¨ä»»åŠ¡æäº¤é˜¶æ®µä¸Šä¼ ä¾èµ–çš„ jarã€‚</p>

<h5 id="toc_14">å…³é—­æ¨æµ‹æ‰§è¡Œï¼ˆSpeculative Executionï¼‰</h5>

<p>æ‰€è°“æ¨æµ‹æ‰§è¡Œæ˜¯è¿™æ ·ä¸€ç§æœºåˆ¶ï¼šåœ¨é›†ç¾¤ç¯å¢ƒä¸‹è¿è¡Œ MapReduceï¼Œä¸€ä¸ª job ä¸‹çš„å¤šä¸ª task æ‰§è¡Œé€Ÿåº¦ä¸ä¸€è‡´ï¼Œæ¯”å¦‚æœ‰çš„ä»»åŠ¡å·²ç»å®Œæˆï¼Œä½†æ˜¯æœ‰äº›ä»»åŠ¡å¯èƒ½åªè·‘äº†10%ï¼Œè¿™äº›ä»»åŠ¡å°†ä¼šæˆä¸ºæ•´ä¸ª job çš„çŸ­æ¿ã€‚æ¨æµ‹æ‰§è¡Œä¼šå¯¹è¿è¡Œæ…¢çš„ task å¯åŠ¨å¤‡ä»½ä»»åŠ¡ï¼Œç„¶åä»¥å…ˆè¿è¡Œå®Œæˆçš„ task çš„ç»“æœä¸ºå‡†ï¼Œkill æ‰å¦å¤–ä¸€ä¸ª taskã€‚è¿™ä¸ªç­–ç•¥å¯ä»¥æå‡ job çš„ç¨³å®šæ€§ï¼Œåœ¨ä¸€äº›æç«¯æƒ…å†µä¸‹åŠ å¿« job çš„æ‰§è¡Œé€Ÿåº¦ã€‚</p>

<p>Sqoop é»˜è®¤çš„åˆ†ç‰‡ç­–ç•¥æ˜¯æŒ‰ç…§æ•°æ®åº“çš„ä¸»é”®å’Œ Mapper æ•°é‡æ¥å†³å®šæ¯ä¸ªåˆ†ç‰‡æ‹‰å–çš„æ•°æ®é‡ã€‚å¦‚æœä¸»é”®ä¸æ˜¯å•è°ƒé€’å¢æˆ–è€…é€’å¢çš„æ­¥é•¿æœ‰å¤§å¹…æ³¢åŠ¨ï¼Œåˆ†ç‰‡å°±ä¼šå‡ºç°æ•°æ®å€¾æ–œã€‚å¯¹äºä¸€ä¸ªæ•°æ®é‡è¾ƒå¤§çš„è¡¨æ¥è¯´ï¼Œé€‚åº¦çš„æ•°æ®å€¾æ–œæ˜¯ä¸€å®šä¼šå­˜åœ¨çš„æƒ…å†µï¼Œå½“ Mapper ç»“æŸæ—¶é—´ä¸å‡è€Œè§¦å‘æ¨æµ‹æ‰§è¡Œæœºåˆ¶æ—¶ï¼ŒMySQL çš„æ•°æ®è¢«é‡å¤ä¸”å¹¶å‘çš„è¯»å–ï¼Œå ç”¨äº†å¤§é‡ io èµ„æºï¼Œä¹Ÿä¼šå½±å“åˆ°å…¶ä»–åŒæ­¥çš„ä»»åŠ¡ã€‚åœ¨ä¸€ä¸ª Hadoop é›†ç¾¤ä¸­ï¼Œæˆ‘ä»¬ä»ç„¶è®¤ä¸ºä¸€ä¸ªèŠ‚ç‚¹ä¸å¯ç”¨å¯¼è‡´æ•´ä¸ª MapReduce å¤±è´¥ä»ç„¶æ˜¯å°æ¦‚ç‡äº‹ä»¶ï¼Œå¯¹è¿™ç§é”™è¯¯ï¼Œåœ¨è°ƒåº¦å™¨ä¸Šå¢åŠ é‡è¯•å°±å¯ä»¥å¾ˆå¥½çš„è§£å†³é—®é¢˜è€Œä¸æ˜¯ä¾èµ–æ¨æµ‹æ‰§è¡Œæœºåˆ¶ã€‚</p>

<h3 id="toc_15">ç›‘æ§å’ŒæŠ¥è­¦</h3>

<p>æ ¹æ® <a href="http://ylzheng.com/2018/02/02/monitor-best-praticase4-golden-signals/"><strong>USE</strong></a> åŸåˆ™ï¼Œå¤§æ¦‚æ•´ç†å‡ºä¸‹é¢å‡ ä¸ªéœ€è¦ç›‘æ§çš„æŒ‡æ ‡ï¼š</p>

<ul>
<li>MySQL æœºå™¨çš„è´Ÿè½½ï¼ŒIOPSï¼Œå‡ºå…¥å¸¦å®½</li>
<li>è°ƒåº¦é˜Ÿåˆ—é•¿åº¦ï¼ŒYarn æäº¤é˜Ÿåˆ—é•¿åº¦</li>
<li>ä»»åŠ¡æ‰§è¡Œé”™è¯¯æ•°</li>
</ul>

<p>æŠ¥è­¦æ›´å¤šæ˜¯é’ˆå¯¹é˜Ÿåˆ—é¥±å’Œåº¦å’ŒåŒæ­¥é”™è¯¯è¿›è¡Œçš„</p>

<h3 id="toc_16">å’Œç¦»çº¿ä½œä¸šè°ƒåº¦å™¨é›†æˆ</h3>

<h2 id="toc_17">å±•æœ›</h2>

<p>æ•°æ®åŒæ­¥å‘å±•åˆ°æ¯”è¾ƒå¤šçš„ä»»åŠ¡åï¼Œæ–°å¢çš„åŒæ­¥ä»»åŠ¡è¶Šæ¥è¶Šå¤šï¼Œåˆ é™¤çš„é€Ÿåº¦è¿œè¿œè·Ÿä¸ä¸Šæ–°å¢çš„é€Ÿåº¦ï¼Œæ€»ä½“æ¥è¯´åŒæ­¥çš„å‹åŠ›ä¼šè¶Šæ¥è¶Šå¤§ï¼Œéœ€è¦ä¸€ä¸ªæ›´å¥½çš„æœºåˆ¶å»å‘ç°æ— ç”¨çš„åŒæ­¥ä»»åŠ¡å¹¶é€šçŸ¥ä¸šåŠ¡åˆ é™¤ï¼Œå‡è½»å¹³å°çš„å‹åŠ›ã€‚</p>

<p>å¦å¤–å°±æ˜¯æ•°æ®æºçš„æ”¯æŒä¸å¤Ÿï¼ŒHive å’Œ HBaseã€ElasticSearch äº’é€šå·²ç»æˆäº†ä¸€ä¸ªå‘¼å£°å¾ˆå¼ºçƒˆçš„éœ€æ±‚ã€‚Hive è™½ç„¶å¯ä»¥é€šè¿‡æŒ‚å¤–éƒ¨è¡¨ç”¨ SQL çš„æ–¹å¼å†™å…¥æ•°æ®ï¼Œä½†æ˜¯æ•ˆç‡ä¸é«˜æœ‰å¾ˆéš¾æ§åˆ¶å¹¶å‘ï¼Œå¾ˆå®¹æ˜“å½±å“åˆ°çº¿ä¸Šé›†ç¾¤ï¼Œéœ€è¦æœ‰æ›´å¥½çš„å®ç°æ–¹æ¡ˆæ‰èƒ½åœ¨ç”Ÿäº§ç¯å¢ƒçœŸæ­£çš„è¿è¡Œèµ·æ¥ã€‚</p>

<p>å¦å¤–è¿™é‡Œæ²¡æœ‰è°ˆåˆ°çš„ä¸€ä¸ªè¯é¢˜å°±æ˜¯æµå¼æ•°æ®å¦‚ä½•åšåŒæ­¥ï¼Œä¸€ä¸ªå…¸å‹çš„åœºæ™¯å°±æ˜¯ Kafka çš„æ—¥å¿—å®æ—¶è½åœ°ç„¶åå®æ—¶è¿›è¡Œ OLAP çš„æŸ¥è¯¢ï¼Œæˆ–è€…é€šè¿‡ MySQL binlog å®æ—¶æ›´æ–° ElasticSearch çš„ç´¢å¼•ã€‚å…³äºè¿™å—çš„åŸºç¡€è®¾ç½®çŸ¥ä¹ä¹Ÿåœ¨å¿«é€Ÿå»ºè®¾ä¸­ï¼Œéå¸¸æ¬¢è¿æ„Ÿå…´è¶£åŒå­¦æŠ•ç®€å†åˆ° <a href="mailto:ck@zhihu.com">ck@zhihu.com</a> ï¼ŒåŠ å…¥çŸ¥ä¹å¤§æ•°æ®è®¡ç®—å¹³å°ç»„ã€‚</p>

<h2 id="toc_18">å‚è€ƒèµ„æ–™</h2>

<ul>
<li><a href="https://chu888chu888.gitbooks.io/hadoopstudy/content/Content/9/datax/datax.html">Datax æ€§èƒ½å¯¹æ¯”</a></li>
<li><a href="https://blog.csdn.net/zhaodedong/article/details/54177686">æ¼«è°ˆæ•°æ®ä»“åº“ä¹‹æ‹‰é“¾è¡¨</a></li>
<li><a href="https://orc.apache.org/">Apache ORC</a></li>
<li><a href="http://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html">Apache Sqoop</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2018-07-05T21:00:20+08:00" itemprop="datePublished">2018/7/5</time>
			</div>
			
			 
			
		</div>
		<h1 class="title" itemprop="name"><a href="15307956203332.html" itemprop="url">
		Sqoop ä½¿ç”¨æŒ‡å—</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>Sqoop æ˜¯ä¸€ä¸ªæ•°æ®åŒæ­¥å·¥å…·ï¼Œç”¨äºå…³ç³»å‹æ•°æ®åº“å’Œå„ç§å¤§æ•°æ®å­˜å‚¨æ¯”å¦‚ Hive ä¹‹é—´çš„æ•°æ®ç›¸äº’åŒæ­¥ã€‚Sqoop å› ä¸ºå®ƒçš„ä½¿ç”¨ä¾¿åˆ©å¾—åˆ°äº†å¹¿æ³›ä½¿ç”¨ã€‚ç±»ä¼¼çš„å·¥å…·è¿˜æœ‰é˜¿é‡Œå¼€æºçš„ <a href="https://github.com/alibaba/DataX">DataX</a> å’Œå…¶ä»–å•†ä¸šå·¥å…·ã€‚</p>

<p><a href="http://sqoop.apache.org/docs/1.99.7/index.html">Sqoop 2.0</a> ä¸»è¦è§£å†³ Sqoop 1.x æ‰©å±•éš¾çš„é—®é¢˜ï¼Œæå‡ºçš„ Server-Client æ¨¡å‹ï¼Œå…·ä½“ç”¨çš„ä¸æ˜¯ç‰¹åˆ«å¤šã€‚æœ¬æ–‡ä¸»è¦ä»‹ç»çš„è¿˜æ˜¯ Sqoop 1.xï¼Œæœ€æ–°çš„ Sqoop ç‰ˆæœ¬æ˜¯ 1.4.7</p>

<h3 id="toc_0">å®‰è£…</h3>

<p>Sqoop å®‰è£…éœ€è¦ä¾èµ– Hadoop å’Œ Hiveï¼Œä»¥ Debain ä¸ºä¾‹ï¼Œå®‰è£… Sqoop ä¹Ÿæ¯”è¾ƒç®€å•ã€‚</p>

<pre><code class="language-bash">apt-get install hadoop hive hive-hbase hive-hcatalog sqoop
</code></pre>

<p>é™¤æ­¤ä¹‹å¤–ï¼Œé’ˆå¯¹ä¸åŒçš„æ•°æ®æºï¼Œéœ€è¦ä¸åŒçš„ JDBC Driverï¼Œè¿™ä¸ªæ˜¯ Sqoop é»˜è®¤æ²¡æœ‰è‡ªå¸¦çš„åº“ï¼Œéœ€è¦è‡ªè¡Œå®‰è£…ã€‚æ¯”å¦‚ MySQL çš„ Driver æ˜¯ <code>mysql-connector-java-5.1.13-bin.jar</code> ï¼Œç¡®ä¿ Jar åŒ…åœ¨ Sqoop çš„ classpath å†…å°±è¡Œã€‚</p>

<h3 id="toc_1">æ•°æ®æº</h3>

<p>Sqoop æ”¯æŒéå¸¸å¤šçš„æ•°æ®æºï¼Œç†è®ºä¸Šæ‰€æœ‰æ”¯æŒ JDBC çš„æ•°æ®æºéƒ½å¯ä»¥ä½œä¸º Sqoop çš„æ•°æ®æºã€‚æœ€å¸¸è§çš„åœºæ™¯è¿˜æ˜¯ä»å…³ç³»å‹æ•°æ®ï¼ˆRDBMSï¼‰å¯¼å…¥åˆ° Hive, HBase æˆ–è€… HDFSã€‚</p>

<p>Sqoop çš„æ‰©å±•æ€§æ²¡æœ‰æƒ³è±¡ä¸­çš„é‚£ä¹ˆå¥½ï¼Œä½†æ˜¯å› ä¸ºå¤§éƒ¨åˆ†ä¼ä¸šçš„æ•°æ®ä»“åº“è¿˜æ˜¯æ„å»ºåœ¨ä¼ ç»Ÿçš„ Hive å’Œ HBase ä¹‹ä¸Šçš„ï¼ŒSqoop è¿˜æ˜¯å¯ä»¥æ»¡è¶³ 80% çš„æ•°æ®åŒæ­¥éœ€æ±‚çš„ã€‚</p>

<p>ä¸€ä¸ªç®€å•ä»¥ MySQL ä½œä¸ºä¸Šæ¸¸æ•°æ®æºçš„åŒæ­¥ï¼š</p>

<pre><code class="language-bash">sqoop import --connect jdbc:mysql://database.example.com/employees \
  --username dbuser --password &quot;&quot; 
</code></pre>

<p>Sqoop æ”¯æŒå°†æ•°æ®åŒæ­¥åˆ° HDFS æˆ–è€…ç›´æ¥åˆ° Hiveï¼š</p>

<pre><code class="language-bash">sqoop import --connect jdbc:mysql://database.example.com/employees \
  --username dbuser --password &quot;&quot; --table employees \
  --hive-import --hive-overwrite \
  --hive-database employees --hive-table employees
</code></pre>

<h3 id="toc_2">å­˜å‚¨æ ¼å¼</h3>

<p>å­˜å‚¨æ ¼å¼ä¸»è¦æ˜¯ Hive çš„æ¦‚å¿µï¼Œä½†æ˜¯å¯¹äºæ•°æ®åŒæ­¥æ¥è®²ï¼Œæ ¼å¼çš„é€‰æ‹©ä¼šå½±å“åŒæ­¥æ•°æ®ï¼Œç±»å‹ç³»ç»Ÿçš„å…¼å®¹æ€§ç­‰ç­‰ï¼Œæˆ‘ä»¬å¿…é¡»äºˆä»¥å…³æ³¨ã€‚å‚è€ƒä¸‹é¢çš„è¡¨æ ¼ï¼š</p>

<table>
<thead>
<tr>
<th></th>
<th>å‹ç¼©æ¯”</th>
<th>é¢„è®¡ç®—</th>
<th>ç±»å‹å…¼å®¹æ€§</th>
</tr>
</thead>

<tbody>
<tr>
<td>TextFile</td>
<td>æ— </td>
<td>å¦</td>
<td>ä¸€èˆ¬</td>
</tr>
<tr>
<td>SequenceFile</td>
<td>ä¸­</td>
<td>å¦</td>
<td>ä¸€èˆ¬</td>
</tr>
<tr>
<td>Parquet</td>
<td>é«˜</td>
<td>æ˜¯ï¼ˆsqoop ä¾èµ–çš„ç‰ˆæœ¬ feature ä¸å®Œæ•´ï¼‰</td>
<td>å¥½</td>
</tr>
<tr>
<td>ORC</td>
<td>é«˜</td>
<td>æ˜¯</td>
<td>å¥½</td>
</tr>
</tbody>
</table>

<p>Hive é»˜è®¤çš„å­˜å‚¨æ ¼å¼æ˜¯ TextFileï¼ŒTextFile ç±»ä¼¼ä¸€ä¸ª CSV æ–‡ä»¶ï¼Œä½¿ç”¨ä¸å¯è§æœåŠ¡åˆ†å‰²åˆ—ï¼ŒåŒæ­¥åçš„æ•°æ®å¯è¯»æ€§æ¯”è¾ƒå¥½ã€‚ä½†æ˜¯å› ä¸ºæ‰€æœ‰æ•°æ®éƒ½æ˜¯æŒ‰æ–‡æœ¬å­˜å‚¨çš„ï¼Œå¯¹äºæŸäº›ç±»å‹ï¼ˆæ¯”å¦‚ blob/bit ï¼‰æ— æ³•æ”¯æŒã€‚</p>

<p>Parquet/ORC éƒ½æ˜¯åˆ—å¼å­˜å‚¨æ ¼å¼ï¼Œè¿™é‡Œä¸å¤šä»‹ç»ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ›´å€¾å‘äºé€‰æ‹© Parquet/ORC ï¼ŒèŠ‚çœç©ºé—´çš„åŒæ—¶åœ¨ Hive ä¸Šçš„æŸ¥è¯¢é€Ÿåº¦ä¹Ÿæ›´å¿«ã€‚</p>

<p>åŒæ­¥ä¸º Parquet æ ¼å¼ï¼š</p>

<pre><code class="language-bash">sqoop import --connect jdbc:mysql://database.example.com/employees \
 --username dbuser --password &quot;&quot; --table employees \
 --hive-import --hive-overwrite \
 --hive-database employees --hive-table employees \
 --as-parquetfile
</code></pre>

<p>å¦‚æœè¦å¯¼å‡ºä¸º ORC æ ¼å¼ï¼Œéœ€è¦å€ŸåŠ© Hive æä¾›çš„ä¸€ä¸ªç»„ä»¶ HCatalogï¼ŒåŒæ­¥è¯­æ³•ä¹Ÿç¨ç¨ä¸å¤ªä¸€æ ·</p>

<pre><code class="language-bash">sqoop import --connect jdbc:mysql://database.example.com/employees \
 --username dbuser --password &quot;&quot; --table employees \
 --drop-and-create-hcatalog-table \
 --hcatalog-database employees --hcatalog-table employees \
 --hcatalog-storage-stanza &quot;STORED AS ORC&quot;
</code></pre>

<p>Parquet ç†è®ºä¸Šä¹Ÿå¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼åŒæ­¥ï¼Œä¸è¿‡å®æµ‹å½“å‰ Sqoop ç‰ˆæœ¬ (1.4.7) è¿˜æ˜¯æœ‰ BUGï¼Œè¿˜æ˜¯ç­‰ç­‰å§ã€‚</p>

<h3 id="toc_3">ç±»å‹çš„å…¼å®¹æ€§</h3>

<p>ç”±äºæ•°æ®æºæ”¯æŒçš„ç±»å‹å’Œ Hive æœ¬èº«å¯èƒ½ä¸å¤ªä¸€æ ·ï¼Œæ‰€ä»¥å¿…ç„¶å­˜åœ¨ç±»å‹è½¬æ¢çš„é—®é¢˜ã€‚å®é™…åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ä¹Ÿæ˜¯éå¸¸å¤´ç–¼çš„ä¸€ä»¶äº‹ã€‚å¯¹äº Hive æ¥è¯´ï¼Œæ”¯æŒçš„ç±»å‹å–å†³äºé‡‡ç”¨çš„å­˜å‚¨æ ¼å¼ã€‚ä»¥ MySQL ä¸ºä¾‹ï¼Œå½“å­˜å‚¨æ ¼å¼ä¸º Hive æ—¶ï¼ŒåŸºæœ¬çš„ç±»å‹æ˜ å°„å¦‚ä¸‹ï¼š</p>

<pre><code>MySQL(bigint) --&gt; Hive(bigint) 
MySQL(tinyint) --&gt; Hive(tinyint) 
MySQL(int) --&gt; Hive(int) 
MySQL(double) --&gt; Hive(double) 
MySQL(bit) --&gt; Hive(boolean) 
MySQL(varchar) --&gt; Hive(string) 
MySQL(decimal) --&gt; Hive(double) 
MySQL(date/timestamp) --&gt; Hive(string)
</code></pre>

<p>è¿™é‡Œçš„ç±»å‹æ˜ å°„å¹¶ä¸å®Œå…¨å‡†ç¡®ï¼Œå› ä¸ºè¿˜å–å†³äºç›®æ ‡å­˜å‚¨æ ¼å¼æ”¯æŒçš„ç±»å‹ã€‚</p>

<p>ç”±äº Text æ ¼å¼éå¸¸ç±»ä¼¼ CSVï¼Œä½¿ç”¨æ–‡æœ¬å­˜å‚¨æ‰€æœ‰æ•°æ®ï¼Œå¯¹äº <code>Binary/Blob</code> è¿™æ ·çš„ç±»å‹å°±æ— æ³•æ”¯æŒã€‚Parquet/ORC/Avro å› ä¸ºå¼•å…¥äº†åºåˆ—åŒ–åè®®ï¼Œæœ¬èº«å­˜å‚¨æ˜¯åŸºäºäºŒè¿›åˆ¶çš„ï¼Œæ‰€ä»¥å¯ä»¥æ”¯æŒç»å¤§éƒ¨åˆ†ç±»å‹ã€‚</p>

<p>å¦‚æœä½ åœ¨ä½¿ç”¨ TextFile éœ€è¦æ³¨æ„ä¸‹é¢çš„é—®é¢˜ï¼š</p>

<ul>
<li>ä¸Šæ¸¸æ•°æ®æºä¸­çš„ <code>NULL</code> ä¼šè¢«è½¬åŒ–ä¸ºå­—ç¬¦ä¸²çš„ <code>NULL</code>, Hive ä¸­çš„ <code>NULL</code> ç”¨ <code>\N</code> è¡¨ç¤º</li>
<li>å¦‚æœå†…å®¹ä¸­å«æœ‰æ¢è¡Œç¬¦ï¼ŒåŒæ­¥åˆ° Hive ä¸­ä¼šè¢«å½“åšç‹¬ç«‹çš„ä¸¤è¡Œæ¥å¤„ç†ï¼Œé€ æˆæŸ¥è¯¢ç»“æœå’Œå®é™…æ•°æ®ä¸ç›¸ç¬¦</li>
</ul>

<p>å¤„ç†æ–¹æ³•æ¯”è¾ƒç®€å•</p>

<p>å¦‚æœåœ¨ä½¿ç”¨ Parquetï¼Œè¦æ³¨æ„ Sqoop è‡ªå¸¦çš„ Parquet åº“ç‰ˆæœ¬æ¯”è¾ƒæ—§ï¼Œä¸æ”¯æŒ DateTime/Timestamp ç±»å‹çš„æ•°æ®ï¼Œè€Œæ˜¯ä¼šç”¨ä¸€ä¸ªè¡¨ç¤º ms çš„ BIGINT æ¥ä»£æ›¿ï¼Œåˆ†ææ•°æ®çš„æ—¶å€™åº”è¯¥æ³¨æ„è¿™ç‚¹ã€‚</p>

<h3 id="toc_4">æ•°æ®æ ¡éªŒ</h3>

<p>Sqoop å†…å»ºæœ‰ validate æœºåˆ¶ï¼Œåªèƒ½éªŒè¯å•è¡¨çš„ row count: <a href="https://sqoop.apache.org/docs/1.4.3/SqoopUserGuide.html#validation">Sqoop User Guide (v1.4.3)</a></p>

<h3 id="toc_5">å¢é‡å¯¼å…¥</h3>

<p>å¯¹äºæ•°æ®é‡å¾ˆå¤§çš„åº“ï¼Œå…¨é‡åŒæ­¥ä¼šéå¸¸ç—›ï¼Œä½†æ˜¯å¦‚æœå¯ä»¥é€‰æ‹©è¿˜æ˜¯å°½å¯èƒ½çš„é€‰æ‹©å…¨é‡åŒæ­¥ï¼Œè¿™ç§åŒæ­¥æ¨¡å¼å¯¹æ•°æ®ä¸€è‡´æ€§çš„ä¿è¯æœ€å¥½ï¼Œæ²¡æœ‰çŠ¶æ€ã€‚å¦‚æœä¸å¾—ä¸è¿›è¡Œå¢é‡åŒæ­¥ï¼Œå¯ä»¥ç»§ç»­å¾€åçœ‹ã€‚</p>

<p>å¢é‡å¯¼å…¥å¯¹ä¸šåŠ¡æ˜¯æœ‰ä¸€å®šä¾µå…¥çš„ï¼ŒSchema çš„è®¾è®¡å’Œæ•°æ®å†™å…¥æ¨¡å¼éœ€è¦éµå®ˆä¸€å®šçš„è§„èŒƒï¼š</p>

<ul>
<li>å¢é‡åŒæ­¥è¡¨ï¼Œæœ€å¥½æœ‰ä¸€ä¸ª Primary Key ï¼Œæœ€å¥½æ˜¯å•è°ƒé€’å¢çš„ ID</li>
<li>æ•°æ®çš„å†™å…¥æ¨¡å¼æ»¡è¶³ä¸‹é¢ä¸¤ç§æƒ…å½¢ä¹‹ä¸€

<ul>
<li>ï¼ˆAppendï¼‰è¡¨çš„å†…å®¹ç±»ä¼¼æ—¥å¿—ï¼Œä¸€æ¬¡å†™å…¥ä¸åšä¿®æ”¹å’Œåˆ é™¤</li>
<li>ï¼ˆLastModifiedï¼‰è¡¨çš„å†…å®¹æœ‰ä¿®æ”¹å’Œåˆ é™¤ï¼Œä½†æ˜¯åˆ é™¤æ“ä½œæ˜¯é€»è¾‘åˆ é™¤ï¼Œæ¯”å¦‚ç”¨ <code>is_deleted</code> å­—æ®µæ ‡è¯†ï¼Œå¹¶ä¸”æœ‰ä¸€ä¸ªæœ€åæ›´æ–°çš„æ—¶é—´æˆ³æ¯”å¦‚ <code>updated_at</code>ï¼Œ<code>updated_at</code> ä¸Šæœ‰ç´¢å¼•ã€‚</li>
</ul></li>
</ul>

<p>å¢é‡çš„æ•°æ®åŒæ­¥å¤§è‡´åˆ†ä¸º 2 ä¸ªé˜¶æ®µï¼šè¯»å–å¢é‡æ•°æ®å’Œåˆå¹¶æ•°æ®ã€‚å¯¹ Sqoop æ¥è¯´ï¼Œå¢é‡åŒæ­¥éœ€è¦ <a href="http://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html#_literal_sqoop_metastore_literal">sqoop-metastore</a> çš„æ”¯æŒï¼Œç”¨äºä¿å­˜ä¸Šæ¬¡åŒæ­¥çš„ä½ç½®ã€‚</p>

<p>æ¯”å¦‚å¯¹äº Append æ¨¡å¼ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€å¼ è¡¨å« <code>employees</code>ï¼ŒPrimary Key æ˜¯ <code>id</code>ï¼Œä¸Šä¸€æ¬¡åŒæ­¥åˆ° <code>id &lt;= 10000</code> çš„æ•°æ®ï¼š</p>

<pre><code class="language-bash">sqoop import --connect jdbc:mysql://database.example.com/employees \
  --username dbuser --password &quot;&quot; --table employees \
  --target-dir &lt;path/to/hive/table/location&gt; \
  --incremental append --check-column id --last-value 10000
</code></pre>

<p>æˆ‘ä»¬ç›´æ¥å°†æ•°æ® load åˆ°äº† Hive çš„è¡¨ç©ºé—´é‡Œï¼ŒHive å¯ä»¥ç›´æ¥æŸ¥è¯¢åˆ°æœ€æ–°å¢é‡çš„æ•°æ®ã€‚<br/>
å¯¹ LastModified æ¨¡å¼ä¼šç¨å¾®å¤æ‚ä¸€äº›ï¼Œé™¤äº†åŠ è½½å¢é‡æ•°æ®ï¼Œè¿˜æ¶‰åŠæ•°æ®åˆå¹¶çš„é—®é¢˜ï¼Œè¿™é‡Œå”¯ä¸€çš„ä¸»é”®å°±ç‰¹åˆ«é‡è¦äº†ã€‚</p>

<pre><code class="language-bash">sqoop import --connect jdbc:mysql://database.example.com/employees \
  --username dbuser --password &quot;&quot; --table employees \
  --target-dir &lt;path/to/hive/table/location&gt; \
  --incremental lastmodified --check-column updated_at --last-value &#39;2018-07-05 00:00:00&#39;
</code></pre>

<p>Sqoop ä¼šåœ¨åŒæ­¥ç»“æŸåå†å¯åŠ¨ä¸€ä¸ª merge ä»»åŠ¡å¯¹æ•°æ®å»é‡ï¼Œå¦‚æœè¡¨å¤ªå°ï¼Œå¯èƒ½ merge çš„ä»£ä»·æ¯”å…¨é‡åŒæ­¥çš„è¿˜è¦é«˜ï¼Œæˆ‘ä»¬å°±è¦æ…é‡è€ƒè™‘å…¨é‡åŒæ­¥æ˜¯ä¸æ˜¯å€¼å¾—äº†ã€‚</p>

<blockquote>
<p>ç”±äº HDFS ä¸æ”¯æŒä¿®æ”¹æ–‡ä»¶ï¼Œsqoop çš„ <code>--incremental</code> å’Œ <code>--hive-import</code> ä¸èƒ½åŒæ—¶ä½¿ç”¨</p>
</blockquote>

<p>Sqoop ä¹Ÿæä¾›äº†å•ç‹¬çš„ <code>sqoop merge</code> å·¥å…·ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åˆ†å¼€è¿›è¡Œ import å’Œ merge è¿™ä¸¤ä¸ªæ­¥éª¤ã€‚</p>

<h3 id="toc_6">åŠ é€ŸåŒæ­¥</h3>

<p>è¿™ä¸ªå°èŠ‚è®¨è®ºä¸€ä¸‹å¦‚ä½•åŠ å¿« Sqoop çš„åŒæ­¥é€Ÿåº¦ï¼ŒSqoop åŒæ­¥é€Ÿåº¦å¤§è‡´å–å†³äºä¸‹é¢çš„å‡ ä¸ªå› ç´ ï¼š</p>

<ul>
<li>æ•°æ®æºçš„è¯»å–é€Ÿåº¦</li>
<li>HDFS å†™å…¥é€Ÿåº¦</li>
<li>æ•°æ®å€¾æ–œç¨‹åº¦</li>
</ul>

<h5 id="toc_7">æ•°æ®æºçš„è¯»å–é€Ÿåº¦</h5>

<p>å¦‚æœä¸Šæ¸¸æ•°æ®æºæ˜¯ MySQLï¼Œå¯ä»¥è€ƒè™‘æ›´æ¢ SSDï¼Œä¿è¯ MySQL å®ä¾‹çš„è´Ÿè½½ä¸è¦å¤ªé«˜ã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒSqoop å¯ä»¥é€šè¿‡å‚æ•°æ§åˆ¶å¹¶å‘è¯»å–çš„ Mapper ä¸ªæ•°åŠ å¿«è¯»å–é€Ÿåº¦ã€‚</p>

<pre><code class="language-bash">sqoop -m &lt;mapper_num&gt; ......
</code></pre>

<p>æ³¨æ„ <code>-m</code> å¹¶ä¸æ˜¯è¶Šå¤§è¶Šé«˜ï¼Œå¹¶å‘æ•°è¿‡é«˜ä¼šæŠŠæ•°æ®åº“å®ä¾‹æ‰“æ­»ï¼ŒåŒæ­¥é€Ÿåº¦åè€Œå˜æ…¢ã€‚</p>

<p>Sqoop é»˜è®¤ä¼šé€šè¿‡ jdbc çš„ API æ¥è¯»å–æ•°æ®ï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡å‚æ•°æ§åˆ¶ä½¿ç”¨ MySQL è‡ªå·±çš„ <code>mysqldump</code> æ¥å¯¼å‡ºæ•°æ®ï¼Œè¿™ç§æ–¹å¼æ¯” jdbc å¿«ä¸€äº›ï¼Œç¼ºç‚¹æ˜¯ä½ ä¸èƒ½é€‰æ‹©è¦åŒæ­¥çš„åˆ—ã€‚å¦å¤–åªèƒ½æ”¯æŒç›®æ ‡æ ¼å¼ä¸º Textfileã€‚æ¯”è¾ƒå±€é™ä½†æ˜¯ç‰¹å®šæƒ…å†µä¸‹è¿˜æ˜¯å¾ˆå¥½ä½¿çš„ã€‚</p>

<h5 id="toc_8">HDFS å†™å…¥é€Ÿåº¦</h5>

<p>è¿™ä¸ªé™¤äº†åˆšåˆšæä¾›çš„æ§åˆ¶å¹¶å‘æ•°ï¼Œè¿˜éœ€è¦ä¿è¯ Yarn åˆ†é…ç»™ Sqoop çš„èµ„æºå……è¶³ï¼Œä¸è¦è®©èµ„æºæˆä¸ºåŒæ­¥çš„ç“¶é¢ˆã€‚å¦å¤–ï¼Œå½“æˆ‘ä»¬é€‰æ‹© Parquet/ORC ä½œä¸ºå­˜å‚¨æ ¼å¼æ—¶ï¼Œæ•°æ®åœ¨å†™å…¥çš„æ—¶å€™éœ€è¦åšå¤§é‡çš„é¢„è®¡ç®—ï¼Œè¿™ä¸ªè¿‡ç¨‹æ˜¯æ¯”è¾ƒæ¶ˆè€— CPU å’Œå†…å­˜çš„ï¼Œæˆ‘ä»¬å¯ä»¥æ§åˆ¶ MapReduce å‚æ•°ï¼Œé€‚å½“æé«˜ Sqoop çš„èµ„æºé…é¢ã€‚</p>

<pre><code class="language-bash">sqoop -Dmapreduce.map.cpu.vcores=4 -Dmapreduce.map.memory.mb=8192 ...
</code></pre>

<h5 id="toc_9">æ•°æ®å€¾æ–œ</h5>

<p>Sqoop é»˜è®¤çš„å¯¼å…¥ç­–ç•¥æ˜¯æ ¹æ®ä¸»é”®è¿›è¡Œåˆ†åŒºå¯¼å…¥çš„ï¼Œå…·ä½“çš„å¹¶å‘ç²’åº¦å–å†³äº <code>-m</code> å‚æ•°ã€‚å¦‚æœä¸»é”®ä¸è¿ç»­å‡ºç°å¤§å¹…åº¦è·³è·ƒï¼Œå°±ä¼šå¯¼è‡´ Sqoop å¯¼å…¥çš„æ—¶å€™å‡ºç°ä¸¥é‡çš„æ•°æ®å€¾æ–œã€‚æ¯”å¦‚æŸå¼ è¡¨çš„ä¸»é”®åˆ†å¸ƒæ˜¯è¿™æ ·çš„ï¼š</p>

<pre><code>1
2
3
...
1000
1001
100000
100001
</code></pre>

<p>Sqoop è®¡ç®—æ¯ä¸ª Mapper è¯»å–çš„æ•°æ®èŒƒå›´çš„æ—¶å€™ï¼Œä¼šéµå¾ªå¾ˆç®€å•çš„å…¬å¼è®¡ç®—ï¼š</p>

<pre><code>range = (max(pk) - min(pk)) / mapper
</code></pre>

<p>å‡ ä¹å‡ºç°æ‰€æœ‰çš„æ•°æ® load éƒ½é›†ä¸­åœ¨ç¬¬ä¸€ä¸ª mapper ä¸Šï¼Œæ•´ä½“åŒæ­¥ç›¸å½“äºæ²¡æœ‰å¹¶å‘ã€‚</p>

<p>å‚è€ƒé˜…è¯»ï¼š</p>

<ul>
<li><a href="https://blog.csdn.net/mike_h/article/details/50148309">Hive æ•°æ®å€¾æ–œ (Data Skew) æ€»ç»“ - CSDNåšå®¢</a></li>
<li><a href="http://abhinaysandeboina.blogspot.hk/2017/08/avoiding-data-skew-in-sqoop.html">Avoiding Data Skew in Sqoop</a></li>
<li><a href="https://docs.qingcloud.com/guide/sqoop.html">Sqoop æŒ‡å— â€” QingCloud  æ–‡æ¡£</a></li>
</ul>

<h3 id="toc_10">å¯¼å‡º</h3>

<p>Sqoop æ”¯æŒå°† Hive çš„æ•°æ®å¯¼å‡ºåˆ° MySQLï¼Œæ–¹ä¾¿åœ¨çº¿ç³»ç»Ÿè°ƒç”¨ã€‚</p>

<pre><code>sqoop export --connect jdbc:mysql://database.example.com/employees --table employees --username dbuser --password &quot;&quot; --relaxed-isolation --update-key id --update-mode allowinsert --hcatalog-database employees --hcatalog-table employees
</code></pre>

<p>å€ŸåŠ© HCatalog å¯ä»¥æ¯”è¾ƒè½»æ¾çš„å°† Hive è¡¨çš„æ•°æ®ç›´æ¥å¯¼å‡ºåˆ° MySQLã€‚æ›´å¤šçš„è¯¦æƒ…å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œè¿™é‡Œä¸å¤šä»‹ç»ã€‚</p>

<h3 id="toc_11">æ›´è¿›ä¸€æ­¥</h3>

<p>å¦‚æœæˆ‘ä»¬è¦åŒæ­¥çš„æ•°æ®éå¸¸å¤šï¼Œç®¡ç†åŒæ­¥ä»»åŠ¡æœ¬èº«å°±å˜æˆäº†ä¸€ä»¶å¤æ‚çš„äº‹æƒ…ã€‚æˆ‘ä»¬ä¸ä»…è¦è€ƒè™‘æºæ•°æ®åº“çš„è´Ÿè½½ï¼Œå®‰å…¨æ€§ã€‚è¿˜è¦è€ƒè™‘åŒæ­¥ä»»åŠ¡çš„å¯åŠ¨æ—¶é—´ï¼ŒSchema å˜æ›´ç­‰ç­‰é—®é¢˜ã€‚å®é™…ä½¿ç”¨çš„æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨å†…éƒ¨è‡ªç ”äº†ä¸€ä¸ªå¹³å°ï¼Œç®¡ç† MySQL å’Œ Hive çš„æ•°æ®æºå¹¶å¯¹ Sqoop ä»»åŠ¡åšäº†è°ƒåº¦ã€‚æœ‰ä¸€éƒ¨åˆ†åŠŸèƒ½åœ¨ Sqoop 2.0 å·²ç»å®ç°äº†ã€‚åœ¨å¤§è§„æ¨¡ä½¿ç”¨ sqoop ä¸€å®šè¦æƒ³æ¸…æ¥šè¿ç»´çš„é—®é¢˜ã€‚</p>

<h3 id="toc_12">Reference</h3>

<ul>
<li><a href="https://stackoverflow.com/questions/24987820/not-able-to-run-sqoop-using-oozie">hadoop - Not able to run sqoop using oozie - Stack Overflow</a></li>
<li><a href="https://stackoverflow.com/questions/23250977/how-to-deal-with-sqoop-import-delimiter-issues-r-n">mysql - how to deal with sqoop import delimiter issues \r\n - Stack Overflow</a></li>
<li><a href="https://www.zybuluo.com/aitanjupt/note/209968">ä½¿ç”¨Sqoopä»MySQLå¯¼å…¥æ•°æ®åˆ°Hiveå’ŒHBase åŠè¿‘æœŸæ„Ÿæ‚Ÿ - ä½œä¸šéƒ¨è½ Cmd Markdown ç¼–è¾‘é˜…è¯»å™¨</a></li>
<li><a href="https://community.hortonworks.com/questions/28060/can-sqoop-be-used-to-directly-import-data-into-an.html">Can sqoop be used to directly import data into an ORC table? - Hortonworks</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC">LanguageManual ORC - Apache Hive - Apache Software Foundation</a></li>
<li>Hive å¢é‡åŒæ­¥ï¼š <a href="https://hortonworks.com/blog/four-step-strategy-incremental-updates-hive/">Four-step Strategy for Incremental Updates in Apache Hive</a></li>
<li>ä½¿ç”¨ MERGE INTO æ›´æ–° Hive æ•°æ®ï¼š <a href="https://hortonworks.com/blog/update-hive-tables-easy-way/">Update Hive Tables the Easy Way - Hortonworks</a></li>
<li>SQL MERGE çš„æ€§èƒ½ï¼š <a href="https://hortonworks.com/blog/apache-hive-moving-beyond-analytics-offload-with-sql-merge/">Apache Hive: Moving Beyond Analytics Offload with SQL MERGE - Hortonworks</a></li>
<li><a href="https://community.hortonworks.com/questions/11373/sqoop-incremental-import-in-hive-i-get-error-messa.html">sqoop incremental import in hive I get error message hive not support append mode how to solve that - Hortonworks</a></li>
<li><a href="http://www.hadooptechs.com/sqoop/sqoop-incremental-import-mysql-to-hive">Sqoop Incremental Import | MySQL to Hive | Big Data &amp; Hadoop</a></li>
<li><a href="https://ask.hellobi.com/blog/marsj/4114">Sqoop 1.4.6 å¯¼å…¥å®æˆ˜ (RDBå«MySQLå’ŒOracle) - å¤©å–„æ™ºèƒ½ï¼šä¸“æ³¨äºå•†ä¸šæ™ºèƒ½BIå’Œæ•°æ®åˆ†æã€å¤§æ•°æ®é¢†åŸŸçš„å‚ç›´ç¤¾åŒºå¹³å°</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2018-02-02T15:40:38+08:00" itemprop="datePublished">2018/2/2</time>
			</div>
			
			 
			
		</div>
		<h1 class="title" itemprop="name"><a href="15175572389238.html" itemprop="url">
		ä½¿ç”¨ BigTop æ‰“åŒ… Hadoop å…¨å®¶æ¡¶</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>ä½¿ç”¨ Hadoop è½¯ä»¶å¥½åƒéš¾å…ä¼šè‡ªå·±æ”¹ä¸‹ä»£ç åšäº›å®šåˆ¶ï¼Œæˆ–è€…åœ¨éƒ¨åˆ†ç»„ä»¶çš„ç‰ˆæœ¬é€‰æ‹©ä¸Šæ¿€è¿›ï¼Œå…¶ä»–çš„ç‰ˆæœ¬( æ¯”å¦‚ HDFS)  ä¸Šä¿å®ˆã€‚æœ€è¿‘åœ¨å…¬å¸å‡çº§ Hive åˆ° 2.1.1 ï¼Œä¹Ÿå¯¹ä»£ç åšäº†ä¸€äº›è°ƒæ•´ç¡®ä¿å¯¹ä¸šåŠ¡çš„å…¼å®¹æ€§ï¼Œä¹‹å‰å…¬å¸ä½¿ç”¨çš„æ˜¯ <code>hive-1.2.2-cdh-5.5.0</code> ã€‚cdh çš„å‘å¸ƒèŠ‚å¥å¤ªæ…¢è·Ÿä¸ä¸Šç¤¾åŒºçš„èŠ‚å¥ï¼Œè€Œä¸”æˆªæ­¢åˆ°ç°åœ¨ï¼Œç¤¾åŒºç‰ˆæœ¬çš„ BUG æ•°é‡å’Œç¨³å®šæ€§éƒ½å¯ä»¥æ¥å—è€Œä¸æ˜¯å¿…é¡»é€‰æ‹©å•†ä¸šå…¬å¸ç»™æˆ‘ä»¬æä¾›çš„å‘è¡Œç‰ˆã€‚</p>

<p>å…¬å¸ç”¨çš„æœåŠ¡å™¨æ˜¯ Debian 7/8ï¼Œä¸ºäº†æ–¹ä¾¿çš„æŠŠå®šåˆ¶è¿‡çš„ Hive éƒ¨ç½²åˆ°æœåŠ¡å™¨ï¼Œéœ€è¦å°† Hive æ‰“åŒ…æˆ debï¼Œä¸€ç›´æ²¡æ‰¾åˆ°ç‰¹åˆ«å¥½çš„æ‰“åŒ…æ–¹æ³•ã€‚è¦åšåˆ° Cloudera é‚£æ ·è§„èŒƒçš„ deb éå¸¸ç¹çï¼Œè¦å¤„ç†å¯åŠ¨è„šæœ¬ï¼Œç¯å¢ƒå˜é‡ï¼Œé…ç½®æ–‡ä»¶çš„ alternatives ç­‰ç­‰ã€‚é¡ºç€è¿™ä¸ªæ€è·¯æ‰¾åˆ°äº† Cloudera å®˜æ–¹çš„æ‰“åŒ…å·¥å…· <a href="https://github.com/cloudera/cdh-package">cdh-package</a> ï¼Œä½†æ˜¯è¿™ä¸ªåº“å·²ç»å¤ªé•¿æ—¶é—´æ²¡æœ‰ç»´æŠ¤äº†ï¼Œé‡Œé¢ä¾èµ–çš„ç‰ˆæœ¬ä¿¡æ¯éå¸¸è€æ—§ï¼Œè€Œä¸”è‡ªå·±æµ‹è¯•ä¹Ÿæ²¡è¿è¡ŒæˆåŠŸã€‚ä½†æ˜¯ cdh-package æ˜¯åŸºäº <a href="https://github.com/apache/bigtop">BigTop</a> çš„ï¼ŒBigTop æœ¬èº«çš„ç»´æŠ¤è¿˜ä¸é”™ã€‚</p>

<p>Bigtop éå¸¸æœ‰é‡å¿ƒï¼Œå®ƒçš„ä¸»è¦ç›®æ ‡å°±æ˜¯æ„å»ºä¸€ä¸ª Apache Hadoop ç”Ÿæ€ç³»ç»Ÿçš„åŒ…å’Œäº¤äº’å¼æµ‹è¯•çš„ç¤¾åŒºã€‚è¿™ä¸ªåŒ…æ‹¬å¯¹å„ç±»ä¸åŒçº§åˆ«å·¥ç¨‹è¿›è¡Œæµ‹è¯•(åŒ…ï¼Œå¹³å°ï¼Œè¿è¡Œæ—¶é—´ï¼Œå‡çº§ç­‰...)ï¼Œå®ƒç”±ç¤¾åŒºä»¥å…³æ³¨ç³»ç»Ÿä½œä¸ºä¸€ä¸ªæ•´ä½“å¼€å‘è€Œæ¥ã€‚BigTop å®˜æ–¹é™¤äº†ä»‹ç»æ€ä¹ˆå®‰è£…ä¹‹å¤–æ²¡æœ‰ä»»ä½•ä½¿ç”¨æ–‡æ¡£ï¼Œä¸è¿‡ç ”ç©¶ä»¥åå‘ç°è¿˜ç®—ç®€å•ï¼Œä¸éœ€è¦å¤ªå¤šçš„è¯´æ˜ã€‚</p>

<h3 id="toc_0">å‡†å¤‡ BigTop ç¯å¢ƒ</h3>

<p>å¯ä»¥æ ¹æ®å®˜æ–¹çš„è¯´æ˜æ¥å®‰è£…ï¼Œæˆ‘è¿™é‡Œæ˜¯ç›´æ¥ä» Github æ‹‰äº†ä»£ç ï¼š</p>

<pre><code class="language-bash">git clone https://github.com/apache/bigtop.git
cd bigtop
git checkout release-1.2.1
./gradlew
</code></pre>

<p>ç„¶åæˆ‘ä»¬å¯ä»¥è¿è¡Œ <code>./gradlew tasks</code> çœ‹ä¸‹ BigTop ç»™æˆ‘ä»¬æä¾›çš„å‘½ä»¤ï¼Œå‘½ä»¤éµå¾ªä¸‹é¢çš„æ ¼å¼ <code>./gradlew &lt;package&gt;-&lt;dist&gt;</code> ï¼š</p>

<pre><code class="language-bash">$ ./gradlew tasks
# hide some output
hive-clean - Removing hive component build and output directories
hive-deb - Building DEB for hive artifacts
hive-download - Download hive artifacts
hive-help - List of available tasks for hive
hive-info - Info about hive component build
hive-pkg - Invoking a native binary packaging target deb
hive-relnotes - Preparing release notes for hive. No yet implemented!!!
hive-rpm - Building RPM for hive artifacts
hive-sdeb - Building SDEB for hive artifacts
hive-spkg - Invoking a native binary packaging target sdeb
hive-srpm - Building SRPM for hive artifacts
hive-tar - Preparing a tarball for hive artifacts
hive-version - Show version of hive component
</code></pre>

<p>ç„¶åç¼–è¾‘ <code>bigtop.bom</code> å°†ä¾èµ–çš„ç‰ˆæœ¬æ”¹æˆè‡ªå·±éœ€è¦çš„ç‰ˆæœ¬ï¼Œæ³¨æ„ BigTop è¿™é‡Œä¼šä¼˜å…ˆä½¿ç”¨ bigtop.bom ä¸­å®šä¹‰çš„ç‰ˆæœ¬å·è¦†ç›–æºä»£ç çš„ç‰ˆæœ¬å·ã€‚</p>

<pre><code class="language-json">&#39;hive&#39; {
      name    = &#39;hive&#39;
      relNotes = &#39;Apache Hive&#39;
      version { base = &#39;1.2.1&#39;; pkg = base; release = 1 }
      tarball { destination = &quot;apache-${name}-${version.base}-src.tar.gz&quot;
                source      = destination }
      url     { download_path = &quot;/$name/$name-${version.base}/&quot;
                site = &quot;${apache.APACHE_MIRROR}/${download_path}&quot;
                archive = &quot;${apache.APACHE_ARCHIVE}/${download_path}&quot; }
    }
</code></pre>

<p>ä¸‹é¢å°†ä»‹ç»å¦‚ä½•ç”¨ BigTop æ‰“åŒ… Hive</p>

<h3 id="toc_1">ç”¨ BigTop æ‰“åŒ… Hive</h3>

<p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†ä¸€ä»½ä¿®æ”¹è¿‡çš„ Hive ä»£ç æ‰“åŒ…æˆ deb åŒ…åˆ†å‘åˆ°é›†ç¾¤ï¼Œé¦–å…ˆåœ¨ç¼–è¾‘æœºå™¨ä¸Šå‡†å¤‡ä¸€äº›å¿…è¦çš„ä¾èµ–ï¼š</p>

<pre><code class="language-bash">sudo apt-get update
sudo apt-get install devscripts
sudo apt-get install dh-make
</code></pre>

<p>æ¥ä¸‹æ¥å‡†å¤‡ Hive çš„ä»£ç ï¼ŒBigtop é»˜è®¤æ ¹æ® bom æ–‡ä»¶é‡ŒæŒ‡å®šçš„ç‰ˆæœ¬å·ä»ä¸Šæ¸¸ä¸‹è½½ Hive çš„ä»£ç ï¼Œè§£å‹ç„¶åç¼–è¯‘ã€‚ä½†æ˜¯ç”±äºæˆ‘ä»¬è¦ä½¿ç”¨è‡ªå·±ä¿®æ”¹è¿‡çš„ç‰ˆæœ¬ï¼Œå¯ä»¥ä¿®æ”¹ <code>bigtop.bom</code> ä»å†…éƒ¨ git ä»“åº“ä¸‹è½½ä»£ç ã€‚</p>

<pre><code class="language-grovvy">  &#39;hive&#39; {
      name    = &#39;hive&#39;
      relNotes = &#39;Apache Hive&#39;
      version { base = &#39;2.1.1&#39;; pkg = base; release = 1 }
      tarball { destination = &quot;apache-${name}-${version.base}-src.tar.gz&quot;
                source      = destination }
      git     { repo = &quot;https://exmaple.com:hive/hive&quot;
                ref = &quot;release-2.1.1&quot;
                dir  = &quot;${name}-${version.base}&quot; }
    }
</code></pre>

<p>ç„¶åå°±å¯ä»¥å¼€å§‹æ‰“åŒ…äº†ï¼š</p>

<pre><code class="language-bash">./gradlew hive-deb
</code></pre>

<p>æ³¨æ„ BigTop åœ¨å®ƒçš„ä»“åº“é‡ŒåŒ…å«äº†å¯¹ Hive çš„å‡ ä¸ª patch æ–‡ä»¶ï¼Œæˆ‘è¿™è¾¹æµ‹è¯•çš„æ—¶å€™ä¼šå¯¼è‡´ç¼–è¯‘å¤±è´¥ï¼Œå»ºè®®åˆ é™¤ï¼š</p>

<pre><code class="language-bash">rm -f /bigtop-packages/src/common/hive/*
</code></pre>

<p>ç„¶åæ¸…ç†æ„å»ºç¯å¢ƒï¼Œé‡æ–°æ‰“åŒ…ï¼š</p>

<pre><code class="language-bash">./gradlew hive-clean
./gradlew hive-deb
</code></pre>

<p>å¦‚æœéœ€è¦æ›´æ–°åŒ…ï¼Œå¯ä»¥æå‡ Release numberï¼Œé»˜è®¤æ˜¯ 1 ï¼Œè¿™ä¸ª BigTop åœ¨æ–‡æ¡£é‡Œæ²¡æœ‰æåŠï¼š</p>

<pre><code class="language-bash">BIGTOP_BUILD_STAMP=&lt;release&gt; ./gradlew hive-deb
</code></pre>

<h3 id="toc_2">å‘å¸ƒ deb åŒ…</h3>

<p>çœ‹çœ‹æˆ‘ä»¬æ„å»ºçš„ç»“æœï¼Œäº§ç”Ÿäº†å¾ˆå¤š deb åŒ…ï¼Œè¿™äº›åŒ…éƒ½éœ€è¦ä¸Šä¼ åˆ°å†…éƒ¨çš„ mirror</p>

<pre><code>$ ls -l output/hive/
total 138516
-rw-r--r-- 1 ck ck 78645700 Feb  1 18:32 hive_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck   314946 Feb  1 18:33 hive_2.1.1-1_amd64.build
-rw-r--r-- 1 ck ck     3461 Feb  1 18:32 hive_2.1.1-1_amd64.changes
-rw-r--r-- 1 ck ck    12500 Feb  1 18:18 hive_2.1.1-1.debian.tar.xz
-rw-r--r-- 1 ck ck     1227 Feb  1 18:18 hive_2.1.1-1.dsc
-rw-r--r-- 1 ck ck     1829 Feb  1 18:18 hive_2.1.1-1_source.changes
-rw-r--r-- 1 ck ck 20999949 Feb  1 18:18 hive_2.1.1.orig.tar.gz
-rw-r--r-- 1 ck ck   107906 Feb  1 18:32 hive-hbase_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck   452862 Feb  1 18:32 hive-hcatalog_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck     3632 Feb  1 18:32 hive-hcatalog-server_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck 39029552 Feb  1 18:32 hive-jdbc_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck     3734 Feb  1 18:32 hive-metastore_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck     3738 Feb  1 18:32 hive-server2_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck  2068240 Feb  1 18:32 hive-webhcat_2.1.1-1_all.deb
-rw-r--r-- 1 ck ck     3608 Feb  1 18:32 hive-webhcat-server_2.1.1-1_all.deb
</code></pre>


			
			
		</div>

	</article>
  

</div>
<nav id="pagenavi">
	 
	 <a class="next" href="all_1.html">Next</a> 
	<div class="center"><a href="archives.html">Blog Archives</a></div>

</nav>

</div>



        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>


<script type="text/javascript">
    var disqus_shortname = 'lfyzjck'; 

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<script type="text/javascript">
var disqus_shortname = 'lfyzjck'; 

(function () {
var s = document.createElement('script'); s.async = true;
s.type = 'text/javascript';
s.src = '//' + disqus_shortname + '.disqus.com/count.js';
(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>
  
    
<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>